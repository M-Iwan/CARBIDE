{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T14:21:54.329456Z",
     "start_time": "2026-01-26T14:21:52.497396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import glob\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.io import read_df, write_df\n",
    "from src.data.utils import round_to_significant\n",
    "from src.ml.evaluate import inner_score\n",
    "from src.analysis.aggregate import scores_to_df, study_to_df\n",
    "from src.analysis.stats import *"
   ],
   "id": "986aca7cc8095ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miwan/miniforge3/envs/pmd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aggregate and process results from model training",
   "id": "76c4a6680ce25f60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Aggregated results (aggregated.tar.gz) are provided in the same directory as raw dataset\n",
    "and can be unpacked using:\n",
    "tar -xvf aggregated.tar.gz\n",
    "\"\"\""
   ],
   "id": "568b0b60d889b561",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T14:00:28.702490Z",
     "start_time": "2026-01-26T14:00:28.700720Z"
    }
   },
   "cell_type": "code",
   "source": "global_dir = '../results/training'",
   "id": "e4fb1caaa5d85f17",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "99531b4d5027c78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T09:48:16.630121Z",
     "start_time": "2026-01-19T09:46:04.709952Z"
    }
   },
   "source": [
    "# Combine files made for each fold\n",
    "\n",
    "ddc = defaultdict(int)\n",
    "\n",
    "for file in tqdm(glob.glob(f'{global_dir}/*/*/*/*.joblib'), total=1620*4):\n",
    "    _, _, _, dataset_pt_dpa, model, descriptors, file_name = file.split('/')\n",
    "\n",
    "    if 'ensemble' in file_name:\n",
    "        continue\n",
    "\n",
    "    dataset, pt, dpa = dataset_pt_dpa.split('_')\n",
    "    _, _, test_fold = file_name.rstrip('.joblib').split('_')\n",
    "    df = read_df(file)\n",
    "\n",
    "    if 'preds' in file_name:\n",
    "        df['Signature'] = df['Signature'].apply(lambda sign: ' | '.join(sign))\n",
    "        df['Test_Fold'] = test_fold\n",
    "        out_path = file.replace('.joblib', '.tsv')\n",
    "        write_df(df, out_path)\n",
    "\n",
    "    elif 'scores' in file_name:\n",
    "        df = scores_to_df(df)\n",
    "        df['Test_Fold'] = test_fold\n",
    "        out_path = file.replace('.joblib', '.tsv')\n",
    "        write_df(df, out_path)\n",
    "\n",
    "    elif 'study' in file_name:\n",
    "        df = study_to_df(df)\n",
    "        df['Test_Fold'] = test_fold\n",
    "        df['Model'] = model\n",
    "        df['Descriptors'] = descriptors\n",
    "        out_path = file.replace('.joblib', '.tsv')\n",
    "        write_df(df, out_path)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('File not found, please check your code :c')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 243/4860 [00:04<01:22, 55.74it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "  5%|▌         | 267/4860 [00:04<01:25, 53.61it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 13%|█▎        | 609/4860 [00:11<01:17, 54.72it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 28%|██▊       | 1347/4860 [00:24<01:09, 50.42it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 28%|██▊       | 1353/4860 [00:25<01:08, 51.22it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 35%|███▍      | 1683/4860 [00:30<00:51, 62.15it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 50%|████▉     | 2420/4860 [00:43<00:40, 60.75it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 50%|████▉     | 2427/4860 [00:43<00:40, 59.55it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 64%|██████▍   | 3120/4860 [00:55<00:27, 62.47it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 72%|███████▏  | 3475/4860 [01:03<00:29, 46.52it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 72%|███████▏  | 3481/4860 [01:03<00:29, 47.39it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 72%|███████▏  | 3492/4860 [01:03<00:29, 46.64it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 72%|███████▏  | 3520/4860 [01:04<00:33, 40.39it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 79%|███████▉  | 3835/4860 [01:13<00:21, 47.82it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 79%|███████▉  | 3847/4860 [01:14<00:21, 47.20it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 79%|███████▉  | 3859/4860 [01:14<00:21, 46.96it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 80%|███████▉  | 3875/4860 [01:14<00:26, 36.61it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 86%|████████▋ | 4195/4860 [01:22<00:15, 42.73it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 94%|█████████▍| 4559/4860 [01:31<00:07, 37.94it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      " 94%|█████████▍| 4577/4860 [01:32<00:06, 44.59it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "4923it [01:39, 48.70it/s]                          /wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "4929it [01:39, 50.17it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "4935it [01:39, 49.93it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "4959it [01:40, 48.35it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "5279it [01:47, 52.89it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "5285it [01:47, 51.36it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "5641it [01:54, 53.30it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "5647it [01:55, 52.13it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "5659it [01:55, 50.71it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "6005it [02:02, 53.91it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "6023it [02:02, 51.84it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "6355it [02:09, 54.31it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "6361it [02:09, 54.25it/s]/wuppertal/gptil/Repos/PMD/src/analysis/aggregate.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  study_df = pd.concat(trial_dfs).reset_index(drop=True)\n",
      "6480it [02:11, 49.17it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "6e29dc8263124d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T09:48:39.979805Z",
     "start_time": "2026-01-19T09:48:36.467163Z"
    }
   },
   "source": [
    "# Combine scores into single file on a per dataset_variant-model-descriptor basis\n",
    "\n",
    "ddc_scores = defaultdict(list)\n",
    "\n",
    "for file in tqdm(glob.glob('../results/training/*/*/*/scores*.tsv'), total=1620):\n",
    "    _, _, _, dataset_pt_dpa, model, descriptors, file_name = file.split('/')\n",
    "    dataset, pt, dpa = dataset_pt_dpa.split('_')\n",
    "    _, _, test_fold = file_name.rstrip('.tsv').split('_')\n",
    "    df = read_df(file)\n",
    "    key = (dataset, pt, dpa, model, descriptors)\n",
    "    ddc_scores[key].append(df)\n",
    "\n",
    "for (dataset, pt, dpa, model, descriptors), values in ddc_scores.items():\n",
    "    os.makedirs(f'../results/aggregated/{dataset}_{pt}_{dpa}/', exist_ok=True)\n",
    "    out_path = f'../results/aggregated/{dataset}_{pt}_{dpa}/{model}_{descriptors}_scores.tsv'\n",
    "    df = pd.concat(values).reset_index(drop=True)\n",
    "    df['Model'] = model\n",
    "    df['Descriptors'] = descriptors\n",
    "    write_df(df, out_path)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1620/1620 [00:01<00:00, 817.49it/s]\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T09:48:53.305312Z",
     "start_time": "2026-01-19T09:48:49.790917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine studies into single file on a per dataset_variant-model-descriptor basis\n",
    "\n",
    "ddc_scores = defaultdict(list)\n",
    "\n",
    "for file in tqdm(glob.glob('../results/training/*/*/*/study*.tsv'), total=1620):\n",
    "    _, _, _, dataset_pt_dpa, model, descriptors, file_name = file.split('/')\n",
    "    dataset, pt, dpa = dataset_pt_dpa.split('_')\n",
    "    _, _, test_fold = file_name.rstrip('.tsv').split('_')\n",
    "    df = read_df(file)\n",
    "    key = (dataset, pt, dpa, model, descriptors)\n",
    "    ddc_scores[key].append(df)\n",
    "\n",
    "for (dataset, pt, dpa, model, descriptors), values in ddc_scores.items():\n",
    "    os.makedirs(f'../results/aggregated/{dataset}_{pt}_{dpa}/', exist_ok=True)\n",
    "    out_path = f'../results/aggregated/{dataset}_{pt}_{dpa}/{model}_{descriptors}_studies.tsv'\n",
    "    df = pd.concat(values).reset_index(drop=True)\n",
    "    write_df(df, out_path)"
   ],
   "id": "67a1cfb263e486b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1620/1620 [00:02<00:00, 808.08it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "39501af63b08a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T09:50:31.602221Z",
     "start_time": "2026-01-19T09:49:06.392832Z"
    }
   },
   "source": [
    "# Combine predictions into single file on a per dataset_variant-model-descriptor basis\n",
    "\n",
    "ddc_scores = defaultdict(list)\n",
    "\n",
    "for file in tqdm(glob.glob('../results/training/*/*/*/preds*.tsv'), total=1620):\n",
    "    _, _, _, dataset_pt_dpa, model, descriptors, file_name = file.split('/')\n",
    "    dataset, pt, dpa = dataset_pt_dpa.split('_')\n",
    "    _, _, test_fold = file_name.rstrip('.tsv').split('_')\n",
    "    df = read_df(file)\n",
    "    key = (dataset, pt, dpa, model, descriptors)\n",
    "    ddc_scores[key].append(df)\n",
    "\n",
    "for (dataset, pt, dpa, model, descriptors), values in tqdm(ddc_scores.items(), total=324):\n",
    "    os.makedirs(f'../results/aggregated/{dataset}_{pt}_{dpa}/', exist_ok=True)\n",
    "    out_path = f'../results/aggregated/{dataset}_{pt}_{dpa}/{model}_{descriptors}_preds.tsv'\n",
    "    df = pd.concat(values).reset_index(drop=True)\n",
    "    df['Model'] = model\n",
    "    df['Descriptors'] = descriptors\n",
    "    write_df(df, out_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1620/1620 [00:28<00:00, 57.47it/s]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.70it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "264c66c35bc73469",
   "metadata": {},
   "source": "### Evaluate Inclusion Criteria"
  },
  {
   "cell_type": "code",
   "id": "81077c10ef16372e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:38:43.403298Z",
     "start_time": "2026-01-21T12:38:32.774332Z"
    }
   },
   "source": [
    "# Aggregate results by inclusion criteria and score on overlapping parts of corresponding datasets\n",
    "\n",
    "pts = [\"Cred\", \"Card\", \"Cvas\"]\n",
    "dpas = [\"prr\", \"ror\", \"ic\"]\n",
    "models = [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\"]\n",
    "descriptors = [\"CDDD\", \"MACCS\", \"Klek\", \"RDKit\", \"ChemBERTa\", \"Morgan\"]\n",
    "\n",
    "for pt, dpa, model, desc in tqdm(product(pts, dpas, models, descriptors), total=3*3*3*6):\n",
    "\n",
    "    primary_path = f'../results/aggregated/primary_{pt}_{dpa}/{model}_{desc}_preds.tsv'\n",
    "    secondary_path = f'../results/aggregated/secondary_{pt}_{dpa}/{model}_{desc}_preds.tsv'\n",
    "\n",
    "    primary_df = read_df(primary_path)\n",
    "    secondary_df = read_df(secondary_path)\n",
    "\n",
    "    primary_df = primary_df.rename(columns={\n",
    "        'y_pred': 'y_pred_primary',\n",
    "        'y_score': 'y_score_primary',\n",
    "    })\n",
    "\n",
    "    secondary_df = secondary_df.rename(columns={\n",
    "        'y_pred': 'y_pred_secondary',\n",
    "        'y_score': 'y_score_secondary',\n",
    "    })\n",
    "\n",
    "    overlap_df = pd.merge(primary_df, secondary_df, on=['SMILES', 'Signature', 'Test_Fold', 'Model', 'Descriptors', 'y_true'])\n",
    "\n",
    "    primary_ddc = defaultdict(list)\n",
    "    secondary_ddc = defaultdict(list)\n",
    "\n",
    "    for fold in overlap_df['Test_Fold'].unique():\n",
    "\n",
    "        sub_overlap_df = overlap_df[overlap_df['Test_Fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "        primary_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_primary'],\n",
    "            y_score=sub_overlap_df['y_score_primary']\n",
    "        )\n",
    "\n",
    "        secondary_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_secondary'],\n",
    "            y_score=sub_overlap_df['y_score_secondary']\n",
    "        )\n",
    "\n",
    "        for key, value in primary_score.items():\n",
    "            primary_ddc[key].append(value)\n",
    "\n",
    "        for key, value in secondary_score.items():\n",
    "            secondary_ddc[key].append(value)\n",
    "\n",
    "        primary_ddc['Test_Fold'].append(fold)\n",
    "        secondary_ddc['Test_Fold'].append(fold)\n",
    "\n",
    "    primary_scores_df = pd.DataFrame(primary_ddc)\n",
    "    secondary_scores_df = pd.DataFrame(secondary_ddc)\n",
    "\n",
    "    primary_scores_df['Dataset'] = 'Primary'\n",
    "    secondary_scores_df['Dataset'] = 'Secondary'\n",
    "\n",
    "    scores_df = pd.concat([primary_scores_df, secondary_scores_df])\n",
    "    scores_df['PT'] = pt.capitalize()\n",
    "    scores_df['DPA'] = dpa.upper()\n",
    "    scores_df['Model'] = model\n",
    "    scores_df['Descriptors'] = desc\n",
    "\n",
    "    melt_df = pd.melt(\n",
    "        frame=scores_df, id_vars=['Dataset', 'DPA', 'PT', 'Test_Fold', 'Model', 'Descriptors'],\n",
    "        value_vars=['Balanced Accuracy', 'GeomRS', 'HarmRS', 'F1 Score', 'ROC AUC', 'MCC', 'Accuracy', 'Recall', 'Specificity', 'Precision'],\n",
    "        var_name='Metric', value_name='Value')\n",
    "\n",
    "    out_dir = f'../results/comparison/primary_secondary'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_path = os.path.join(out_dir, f'{pt}_{dpa}_{model}_{desc}_scores.tsv')\n",
    "    write_df(melt_df, out_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:10<00:00, 15.26it/s]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "70b1415669e2a781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:38:46.490749Z",
     "start_time": "2026-01-21T12:38:46.387973Z"
    }
   },
   "source": [
    "# Format to a table\n",
    "\n",
    "dfs = []\n",
    "for file in glob.glob('../results/comparison/primary_secondary/*.tsv'):\n",
    "    dfs.append(read_df(file))\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "mean_df = df.groupby(by=['Dataset', 'Descriptors', 'Metric', 'Model'])['Value'].mean().reset_index(name='Mean')\n",
    "std_df = df.groupby(by=['Dataset', 'Descriptors', 'Metric', 'Model'])['Value'].std().reset_index(name='STD')\n",
    "\n",
    "comb_df = mean_df.merge(std_df, on=['Dataset', 'Descriptors', 'Metric', 'Model'])\n",
    "comb_df['Mean'] = comb_df['Mean'].apply(lambda value: np.round(value, 5))\n",
    "comb_df['STD'] = comb_df['STD'].apply(lambda value: np.round(value, 5))\n",
    "\n",
    "write_df(comb_df, '../results/comparison/dataset_type_detailed.tsv')"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:38:48.232075Z",
     "start_time": "2026-01-21T12:38:48.127181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfs = []\n",
    "for file in glob.glob('../results/comparison/primary_secondary/*.tsv'):\n",
    "    dfs.append(read_df(file))\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "mean_df = df.groupby(by=['Dataset', 'Metric'])['Value'].mean().reset_index(name='Mean')\n",
    "std_df = df.groupby(by=['Dataset', 'Metric'])['Value'].std().reset_index(name='STD')\n",
    "\n",
    "comb_df = mean_df.merge(std_df, on=['Dataset', 'Metric'])\n",
    "comb_df['Mean'] = comb_df['Mean'].apply(lambda value: np.round(value, 5))\n",
    "comb_df['STD'] = comb_df['STD'].apply(lambda value: np.round(value, 5))\n",
    "\n",
    "write_df(comb_df, '../results/comparison/dataset_type.tsv')"
   ],
   "id": "c57484ccbeeef02d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:38:50.474425Z",
     "start_time": "2026-01-21T12:38:50.433364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print as LaTeX rows\n",
    "df = read_df('../results/comparison/dataset_type_detailed.tsv')\n",
    "\n",
    "for dataset in ['Primary', 'Secondary']:\n",
    "\n",
    "    ds_line = \"\\multirow[t]{18}{*}{\" + dataset + \"}\"\n",
    "    print(ds_line)\n",
    "\n",
    "    for model in ['LogisticRegression', 'RandomForestClassifier', 'XGBClassifier']:\n",
    "\n",
    "        ml_line = \"& \\multirow[t]{6}{*}{\" + model + \"}\"\n",
    "        print(ml_line)\n",
    "\n",
    "        sub_df = pl.from_pandas(df).filter((pl.col('Dataset') == dataset) & (pl.col('Model') == model))\n",
    "        sub_df = sub_df.with_columns([\n",
    "            (pl.col('Mean') * 100).round(0).cast(pl.Int16).alias('Mean'),\n",
    "            (pl.col('STD') * 100).round(0).cast(pl.Int16).alias('STD'),\n",
    "        ])\n",
    "\n",
    "        for idx, desc in enumerate(['CDDD', 'ChemBERTa', 'Klek', 'MACCS', 'Morgan', 'RDKit']):\n",
    "            metrics = sub_df.filter(pl.col('Descriptors') == desc)\n",
    "            rc_mean = metrics.filter(pl.col('Metric') == 'Recall')['Mean'].item()\n",
    "            rc_std = metrics.filter(pl.col('Metric') == 'Recall')['STD'].item()\n",
    "            sp_mean = metrics.filter(pl.col('Metric') == 'Specificity')['Mean'].item()\n",
    "            sp_std = metrics.filter(pl.col('Metric') == 'Specificity')['STD'].item()\n",
    "            roc_mean = metrics.filter(pl.col('Metric') == 'ROC AUC')['Mean'].item()\n",
    "            roc_std = metrics.filter(pl.col('Metric') == 'ROC AUC')['STD'].item()\n",
    "            harm_mean = metrics.filter(pl.col('Metric') == 'HarmRS')['Mean'].item()\n",
    "            harm_std = metrics.filter(pl.col('Metric') == 'HarmRS')['STD'].item()\n",
    "\n",
    "            if idx == 0:\n",
    "                pre = \"  &\"\n",
    "            else:\n",
    "                pre = \"& &\"\n",
    "\n",
    "            empty_lines = \" \" * (9 - len(desc))\n",
    "\n",
    "            line = fr\"{pre} {desc} {empty_lines}& {rc_mean} ± {rc_std} & {sp_mean} ± {sp_std} & {roc_mean} ± {roc_std} & {harm_mean} ± {harm_std} \\\\\"\n",
    "            print(line)"
   ],
   "id": "b67335ea1faffa35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow[t]{18}{*}{Primary}\n",
      "& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "  & CDDD      & 57 ± 7 & 52 ± 8 & 56 ± 3 & 53 ± 3 \\\\\n",
      "& & ChemBERTa & 53 ± 8 & 50 ± 7 & 52 ± 3 & 51 ± 2 \\\\\n",
      "& & Klek      & 54 ± 9 & 57 ± 8 & 57 ± 3 & 54 ± 3 \\\\\n",
      "& & MACCS     & 53 ± 14 & 56 ± 15 & 56 ± 2 & 51 ± 4 \\\\\n",
      "& & Morgan    & 58 ± 9 & 56 ± 10 & 59 ± 4 & 56 ± 4 \\\\\n",
      "& & RDKit     & 54 ± 14 & 58 ± 13 & 58 ± 2 & 53 ± 4 \\\\\n",
      "& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "  & CDDD      & 65 ± 12 & 49 ± 13 & 62 ± 3 & 53 ± 6 \\\\\n",
      "& & ChemBERTa & 63 ± 13 & 46 ± 12 & 58 ± 4 & 51 ± 5 \\\\\n",
      "& & Klek      & 55 ± 18 & 57 ± 18 & 60 ± 3 & 50 ± 7 \\\\\n",
      "& & MACCS     & 64 ± 11 & 51 ± 10 & 61 ± 3 & 55 ± 3 \\\\\n",
      "& & Morgan    & 54 ± 18 & 61 ± 18 & 62 ± 3 & 51 ± 7 \\\\\n",
      "& & RDKit     & 65 ± 11 & 50 ± 9 & 62 ± 4 & 55 ± 3 \\\\\n",
      "& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "  & CDDD      & 62 ± 11 & 54 ± 12 & 62 ± 2 & 56 ± 4 \\\\\n",
      "& & ChemBERTa & 62 ± 12 & 49 ± 12 & 59 ± 3 & 52 ± 5 \\\\\n",
      "& & Klek      & 58 ± 13 & 56 ± 13 & 61 ± 4 & 54 ± 5 \\\\\n",
      "& & MACCS     & 60 ± 13 & 57 ± 13 & 62 ± 3 & 55 ± 4 \\\\\n",
      "& & Morgan    & 60 ± 12 & 56 ± 13 & 62 ± 3 & 56 ± 4 \\\\\n",
      "& & RDKit     & 61 ± 12 & 56 ± 11 & 62 ± 3 & 56 ± 4 \\\\\n",
      "\\multirow[t]{18}{*}{Secondary}\n",
      "& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "  & CDDD      & 58 ± 11 & 50 ± 12 & 56 ± 3 & 52 ± 4 \\\\\n",
      "& & ChemBERTa & 54 ± 8 & 50 ± 9 & 52 ± 3 & 50 ± 3 \\\\\n",
      "& & Klek      & 59 ± 9 & 52 ± 9 & 58 ± 4 & 54 ± 4 \\\\\n",
      "& & MACCS     & 57 ± 20 & 52 ± 20 & 58 ± 4 & 47 ± 8 \\\\\n",
      "& & Morgan    & 61 ± 9 & 50 ± 11 & 58 ± 4 & 53 ± 4 \\\\\n",
      "& & RDKit     & 57 ± 19 & 56 ± 19 & 59 ± 4 & 50 ± 7 \\\\\n",
      "& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "  & CDDD      & 71 ± 17 & 39 ± 20 & 61 ± 3 & 44 ± 15 \\\\\n",
      "& & ChemBERTa & 71 ± 16 & 35 ± 16 & 57 ± 5 & 42 ± 12 \\\\\n",
      "& & Klek      & 61 ± 24 & 50 ± 25 & 60 ± 3 & 44 ± 15 \\\\\n",
      "& & MACCS     & 66 ± 14 & 46 ± 15 & 61 ± 4 & 51 ± 8 \\\\\n",
      "& & Morgan    & 63 ± 20 & 50 ± 23 & 62 ± 4 & 47 ± 13 \\\\\n",
      "& & RDKit     & 70 ± 14 & 42 ± 15 & 61 ± 4 & 49 ± 9 \\\\\n",
      "& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "  & CDDD      & 67 ± 12 & 46 ± 14 & 61 ± 3 & 51 ± 8 \\\\\n",
      "& & ChemBERTa & 65 ± 14 & 44 ± 14 & 58 ± 3 & 49 ± 8 \\\\\n",
      "& & Klek      & 62 ± 15 & 51 ± 16 & 61 ± 4 & 52 ± 7 \\\\\n",
      "& & MACCS     & 63 ± 15 & 52 ± 15 & 62 ± 4 & 53 ± 6 \\\\\n",
      "& & Morgan    & 65 ± 14 & 50 ± 16 & 62 ± 3 & 53 ± 7 \\\\\n",
      "& & RDKit     & 64 ± 12 & 50 ± 13 & 62 ± 4 & 53 ± 6 \\\\\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "2325b6b6a02e05f4",
   "metadata": {},
   "source": "### Evaluate DPA metric"
  },
  {
   "cell_type": "code",
   "id": "8cc12dda493651c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T14:22:54.616996Z",
     "start_time": "2026-01-26T14:22:43.234203Z"
    }
   },
   "source": [
    "# Aggregate results by DPA metric and score on overlapping parts of corresponding datasets\n",
    "\n",
    "datasets = ['primary', 'secondary']\n",
    "dpas = [\"prr\", \"ror\", \"ic\"]\n",
    "pts = [\"Cred\", \"Card\", \"Cvas\"]\n",
    "models = [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\"]\n",
    "descriptors = [\"CDDD\", \"MACCS\", \"Klek\", \"RDKit\", \"ChemBERTa\", \"Morgan\"]\n",
    "\n",
    "for dataset, pt, model, desc in tqdm(product(datasets, pts, models, descriptors), total=2*3*3*6):\n",
    "\n",
    "    cred_path = f'../results/aggregated/{dataset}_{pt}_prr/{model}_{desc}_preds.tsv'\n",
    "    card_path = f'../results/aggregated/{dataset}_{pt}_ror/{model}_{desc}_preds.tsv'\n",
    "    cvas_path = f'../results/aggregated/{dataset}_{pt}_ic/{model}_{desc}_preds.tsv'\n",
    "\n",
    "    cred_df = read_df(cred_path)\n",
    "    card_df = read_df(card_path)\n",
    "    cvas_df = read_df(cvas_path)\n",
    "\n",
    "    cred_df = cred_df.rename(columns={\n",
    "        'y_pred': 'y_pred_prr',\n",
    "        'y_score': 'y_score_prr',\n",
    "    })\n",
    "\n",
    "    card_df = card_df.rename(columns={\n",
    "        'y_pred': 'y_pred_ror',\n",
    "        'y_score': 'y_score_ror',\n",
    "    })\n",
    "\n",
    "    cvas_df = cvas_df.rename(columns={\n",
    "        'y_pred': 'y_pred_ic',\n",
    "        'y_score': 'y_score_ic',\n",
    "    })\n",
    "\n",
    "    merge_on = ['SMILES', 'Signature', 'Test_Fold', 'Model', 'Descriptors', 'y_true']\n",
    "\n",
    "    overlap_df = pd.merge(cred_df, card_df, on=merge_on, how='inner').merge(cvas_df, on=merge_on, how='inner')\n",
    "\n",
    "    prr_ddc = defaultdict(list)\n",
    "    ror_ddc = defaultdict(list)\n",
    "    ic_ddc = defaultdict(list)\n",
    "\n",
    "    for fold in overlap_df['Test_Fold'].unique():\n",
    "\n",
    "        sub_overlap_df = overlap_df[overlap_df['Test_Fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "        prr_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_prr'],\n",
    "            y_score=sub_overlap_df['y_score_prr']\n",
    "        )\n",
    "\n",
    "        ror_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_ror'],\n",
    "            y_score=sub_overlap_df['y_score_ror']\n",
    "        )\n",
    "\n",
    "        ic_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_ic'],\n",
    "            y_score=sub_overlap_df['y_score_ic']\n",
    "        )\n",
    "\n",
    "        for key, value in prr_score.items():\n",
    "            prr_ddc[key].append(value)\n",
    "\n",
    "        for key, value in ror_score.items():\n",
    "            ror_ddc[key].append(value)\n",
    "\n",
    "        for key, value in ic_score.items():\n",
    "            ic_ddc[key].append(value)\n",
    "\n",
    "        prr_ddc['Test_Fold'].append(fold)\n",
    "        ror_ddc['Test_Fold'].append(fold)\n",
    "        ic_ddc['Test_Fold'].append(fold)\n",
    "\n",
    "    prr_scores_df = pd.DataFrame(prr_ddc)\n",
    "    ror_scores_df = pd.DataFrame(ror_ddc)\n",
    "    ic_scores_df = pd.DataFrame(ic_ddc)\n",
    "\n",
    "    prr_scores_df['DPA'] = 'PRR'\n",
    "    ror_scores_df['DPA'] = 'ROR'\n",
    "    ic_scores_df['DPA'] = 'IC'\n",
    "\n",
    "    scores_df = pd.concat([prr_scores_df, ror_scores_df, ic_scores_df])\n",
    "    scores_df['Dataset'] = dataset.capitalize()\n",
    "    scores_df['PT'] = pt.capitalize()\n",
    "    scores_df['Model'] = model\n",
    "    scores_df['Descriptors'] = desc\n",
    "\n",
    "    melt_df = pd.melt(\n",
    "        frame=scores_df, id_vars=['Dataset', 'DPA', 'PT', 'Test_Fold', 'Model', 'Descriptors'],\n",
    "        value_vars=['Balanced Accuracy', 'GeomRS', 'HarmRS', 'F1 Score', 'ROC AUC', 'MCC', 'Accuracy', 'Recall', 'Specificity', 'Precision'],\n",
    "        var_name='Metric', value_name='Value')\n",
    "\n",
    "    out_dir = f'../results/comparison/prr_ror_ic'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_path = os.path.join(out_dir, f'{dataset}_{pt}_{model}_{desc}_scores.tsv')\n",
    "    write_df(melt_df, out_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:11<00:00,  9.49it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d7c8a7fde7c304d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:39:08.929316Z",
     "start_time": "2026-01-21T12:39:08.839200Z"
    }
   },
   "source": [
    "dfs = []\n",
    "for file in glob.glob('../results/comparison/prr_ror_ic/*.tsv'):\n",
    "    dfs.append(read_df(file))\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "mean_df = df.groupby(by=['DPA', 'Descriptors', 'Metric', 'Model'])['Value'].mean().reset_index(name='Mean')\n",
    "std_df = df.groupby(by=['DPA', 'Descriptors', 'Metric', 'Model'])['Value'].std().reset_index(name='STD')\n",
    "\n",
    "comb_df = mean_df.merge(std_df, on=['DPA', 'Descriptors', 'Metric', 'Model'])\n",
    "comb_df['Mean'] = comb_df['Mean'].apply(lambda value: np.round(value, 5))\n",
    "comb_df['STD'] = comb_df['STD'].apply(lambda value: np.round(value, 5))\n",
    "\n",
    "write_df(comb_df, '../results/comparison/dpa_metric_detailed.tsv')"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:39:11.090702Z",
     "start_time": "2026-01-21T12:39:11.007534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfs = []\n",
    "for file in glob.glob('../results/comparison/prr_ror_ic/*.tsv'):\n",
    "    dfs.append(read_df(file))\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "mean_df = df.groupby(by=['DPA', 'Metric'])['Value'].mean().reset_index(name='Mean')\n",
    "std_df = df.groupby(by=['DPA', 'Metric'])['Value'].std().reset_index(name='STD')\n",
    "\n",
    "comb_df = mean_df.merge(std_df, on=['DPA', 'Metric'])\n",
    "comb_df['Mean'] = comb_df['Mean'].apply(lambda value: np.round(value, 5))\n",
    "comb_df['STD'] = comb_df['STD'].apply(lambda value: np.round(value, 5))\n",
    "\n",
    "write_df(comb_df, '../results/comparison/dpa_metric.tsv')"
   ],
   "id": "39d9dcfb7b6ec2c3",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:39:13.329427Z",
     "start_time": "2026-01-21T12:39:13.275432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print as LaTeX rows\n",
    "df = read_df('../results/comparison/dpa_metric_detailed.tsv')\n",
    "\n",
    "for dpa_metric in ['PRR', 'ROR', 'IC']:\n",
    "\n",
    "    ds_line = \"\\multirow[t]{18}{*}{\" + dpa_metric + \"}\"\n",
    "    print(ds_line)\n",
    "\n",
    "    for model in ['LogisticRegression', 'RandomForestClassifier', 'XGBClassifier']:\n",
    "\n",
    "        ml_line = \"& \\multirow[t]{6}{*}{\" + model + \"}\"\n",
    "        print(ml_line)\n",
    "\n",
    "        sub_df = pl.from_pandas(df).filter((pl.col('DPA') == dpa_metric) & (pl.col('Model') == model))\n",
    "        sub_df = sub_df.with_columns([\n",
    "            (pl.col('Mean') * 100).round(0).cast(pl.Int16).alias('Mean'),\n",
    "            (pl.col('STD') * 100).round(0).cast(pl.Int16).alias('STD'),\n",
    "        ])\n",
    "\n",
    "        for idx, desc in enumerate(['CDDD', 'ChemBERTa', 'Klek', 'MACCS', 'Morgan', 'RDKit']):\n",
    "            metrics = sub_df.filter(pl.col('Descriptors') == desc)\n",
    "            rc_mean = metrics.filter(pl.col('Metric') == 'Recall')['Mean'].item()\n",
    "            rc_std = metrics.filter(pl.col('Metric') == 'Recall')['STD'].item()\n",
    "            sp_mean = metrics.filter(pl.col('Metric') == 'Specificity')['Mean'].item()\n",
    "            sp_std = metrics.filter(pl.col('Metric') == 'Specificity')['STD'].item()\n",
    "            roc_mean = metrics.filter(pl.col('Metric') == 'ROC AUC')['Mean'].item()\n",
    "            roc_std = metrics.filter(pl.col('Metric') == 'ROC AUC')['STD'].item()\n",
    "            harm_mean = metrics.filter(pl.col('Metric') == 'HarmRS')['Mean'].item()\n",
    "            harm_std = metrics.filter(pl.col('Metric') == 'HarmRS')['STD'].item()\n",
    "\n",
    "            if idx == 0:\n",
    "                pre = \"  &\"\n",
    "            else:\n",
    "                pre = \"& &\"\n",
    "\n",
    "            empty_lines = \" \" * (9 - len(desc))\n",
    "\n",
    "            line = fr\"{pre} {desc} {empty_lines}& {rc_mean} ± {rc_std} & {sp_mean} ± {sp_std} & {roc_mean} ± {roc_std} & {harm_mean} ± {harm_std} \\\\\"\n",
    "            print(line)"
   ],
   "id": "68b9bde8770255f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow[t]{18}{*}{PRR}\n",
      "& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "  & CDDD      & 54 ± 4 & 52 ± 7 & 55 ± 3 & 53 ± 2 \\\\\n",
      "& & ChemBERTa & 51 ± 7 & 53 ± 6 & 52 ± 3 & 51 ± 2 \\\\\n",
      "& & Klek      & 52 ± 7 & 58 ± 4 & 57 ± 3 & 54 ± 3 \\\\\n",
      "& & MACCS     & 50 ± 6 & 59 ± 5 & 56 ± 2 & 54 ± 2 \\\\\n",
      "& & Morgan    & 53 ± 8 & 57 ± 8 & 57 ± 3 & 54 ± 2 \\\\\n",
      "& & RDKit     & 52 ± 6 & 59 ± 4 & 57 ± 2 & 55 ± 2 \\\\\n",
      "& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "  & CDDD      & 62 ± 8 & 48 ± 11 & 58 ± 2 & 53 ± 5 \\\\\n",
      "& & ChemBERTa & 61 ± 11 & 45 ± 11 & 54 ± 3 & 50 ± 4 \\\\\n",
      "& & Klek      & 53 ± 11 & 57 ± 14 & 58 ± 2 & 52 ± 10 \\\\\n",
      "& & MACCS     & 57 ± 9 & 54 ± 8 & 57 ± 3 & 54 ± 3 \\\\\n",
      "& & Morgan    & 53 ± 9 & 61 ± 10 & 59 ± 3 & 55 ± 3 \\\\\n",
      "& & RDKit     & 63 ± 9 & 47 ± 8 & 58 ± 2 & 53 ± 3 \\\\\n",
      "& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "  & CDDD      & 58 ± 7 & 53 ± 7 & 58 ± 1 & 55 ± 2 \\\\\n",
      "& & ChemBERTa & 58 ± 8 & 50 ± 8 & 55 ± 2 & 52 ± 2 \\\\\n",
      "& & Klek      & 53 ± 6 & 59 ± 4 & 58 ± 3 & 55 ± 3 \\\\\n",
      "& & MACCS     & 56 ± 6 & 57 ± 4 & 59 ± 2 & 56 ± 2 \\\\\n",
      "& & Morgan    & 56 ± 7 & 57 ± 7 & 59 ± 2 & 56 ± 2 \\\\\n",
      "& & RDKit     & 57 ± 7 & 55 ± 5 & 59 ± 3 & 55 ± 2 \\\\\n",
      "\\multirow[t]{18}{*}{ROR}\n",
      "& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "  & CDDD      & 48 ± 5 & 58 ± 5 & 54 ± 3 & 52 ± 3 \\\\\n",
      "& & ChemBERTa & 49 ± 6 & 52 ± 6 & 51 ± 2 & 50 ± 2 \\\\\n",
      "& & Klek      & 50 ± 6 & 57 ± 9 & 54 ± 3 & 52 ± 3 \\\\\n",
      "& & MACCS     & 35 ± 6 & 72 ± 4 & 54 ± 2 & 46 ± 5 \\\\\n",
      "& & Morgan    & 53 ± 6 & 56 ± 8 & 56 ± 4 & 54 ± 3 \\\\\n",
      "& & RDKit     & 36 ± 6 & 72 ± 4 & 56 ± 2 & 48 ± 5 \\\\\n",
      "& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "  & CDDD      & 55 ± 9 & 55 ± 10 & 57 ± 3 & 53 ± 3 \\\\\n",
      "& & ChemBERTa & 56 ± 7 & 50 ± 8 & 54 ± 3 & 52 ± 2 \\\\\n",
      "& & Klek      & 35 ± 11 & 74 ± 10 & 57 ± 2 & 45 ± 11 \\\\\n",
      "& & MACCS     & 56 ± 8 & 56 ± 6 & 59 ± 3 & 55 ± 2 \\\\\n",
      "& & Morgan    & 36 ± 8 & 73 ± 8 & 57 ± 3 & 47 ± 5 \\\\\n",
      "& & RDKit     & 56 ± 6 & 54 ± 7 & 58 ± 3 & 55 ± 3 \\\\\n",
      "& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "  & CDDD      & 53 ± 7 & 58 ± 9 & 57 ± 3 & 54 ± 3 \\\\\n",
      "& & ChemBERTa & 52 ± 8 & 54 ± 8 & 54 ± 3 & 52 ± 3 \\\\\n",
      "& & Klek      & 47 ± 8 & 64 ± 7 & 57 ± 3 & 53 ± 4 \\\\\n",
      "& & MACCS     & 46 ± 8 & 66 ± 8 & 58 ± 2 & 53 ± 3 \\\\\n",
      "& & Morgan    & 48 ± 8 & 63 ± 9 & 58 ± 3 & 54 ± 3 \\\\\n",
      "& & RDKit     & 50 ± 6 & 61 ± 6 & 58 ± 3 & 54 ± 3 \\\\\n",
      "\\multirow[t]{18}{*}{IC}\n",
      "& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "  & CDDD      & 65 ± 5 & 41 ± 6 & 55 ± 3 & 50 ± 3 \\\\\n",
      "& & ChemBERTa & 60 ± 5 & 42 ± 4 & 51 ± 2 & 49 ± 2 \\\\\n",
      "& & Klek      & 63 ± 6 & 44 ± 6 & 55 ± 3 & 52 ± 3 \\\\\n",
      "& & MACCS     & 73 ± 7 & 31 ± 6 & 55 ± 3 & 43 ± 5 \\\\\n",
      "& & Morgan    & 66 ± 5 & 42 ± 7 & 56 ± 4 & 51 ± 5 \\\\\n",
      "& & RDKit     & 72 ± 7 & 35 ± 6 & 57 ± 2 & 46 ± 4 \\\\\n",
      "& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "  & CDDD      & 82 ± 10 & 25 ± 13 & 59 ± 2 & 36 ± 14 \\\\\n",
      "& & ChemBERTa & 81 ± 9 & 25 ± 11 & 57 ± 2 & 36 ± 11 \\\\\n",
      "& & Klek      & 80 ± 8 & 27 ± 10 & 58 ± 3 & 39 ± 10 \\\\\n",
      "& & MACCS     & 76 ± 7 & 33 ± 8 & 59 ± 3 & 45 ± 6 \\\\\n",
      "& & Morgan    & 79 ± 10 & 28 ± 12 & 58 ± 2 & 39 ± 11 \\\\\n",
      "& & RDKit     & 79 ± 9 & 31 ± 10 & 60 ± 3 & 43 ± 9 \\\\\n",
      "& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "  & CDDD      & 74 ± 6 & 33 ± 8 & 57 ± 1 & 45 ± 6 \\\\\n",
      "& & ChemBERTa & 74 ± 7 & 30 ± 7 & 55 ± 2 & 42 ± 6 \\\\\n",
      "& & Klek      & 74 ± 7 & 33 ± 6 & 58 ± 3 & 45 ± 5 \\\\\n",
      "& & MACCS     & 74 ± 7 & 35 ± 5 & 59 ± 3 & 47 ± 4 \\\\\n",
      "& & Morgan    & 75 ± 6 & 34 ± 8 & 59 ± 2 & 46 ± 6 \\\\\n",
      "& & RDKit     & 74 ± 6 & 35 ± 6 & 58 ± 3 & 47 ± 4 \\\\\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate Cardiotoxicity Definition",
   "id": "f565a365db1d40b9"
  },
  {
   "cell_type": "code",
   "id": "1a53d021a8b95f46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:39:32.073495Z",
     "start_time": "2026-01-21T12:39:21.023727Z"
    }
   },
   "source": [
    "# Aggregate results by cardiotoxicity definition and score on overlapping parts of corresponding datasets\n",
    "\n",
    "datasets = ['primary', 'secondary']\n",
    "dpas = [\"prr\", \"ror\", \"ic\"]\n",
    "models = [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\"]\n",
    "descriptors = [\"CDDD\", \"MACCS\", \"Klek\", \"RDKit\", \"ChemBERTa\", \"Morgan\"]\n",
    "\n",
    "for dataset, dpa, model, desc in tqdm(product(datasets, dpas, models, descriptors), total=2*3*3*6):\n",
    "\n",
    "    cred_path = f'../results/aggregated/{dataset}_Cred_{dpa}/{model}_{desc}_preds.tsv'\n",
    "    card_path = f'../results/aggregated/{dataset}_Card_{dpa}/{model}_{desc}_preds.tsv'\n",
    "    cvas_path = f'../results/aggregated/{dataset}_Cvas_{dpa}/{model}_{desc}_preds.tsv'\n",
    "\n",
    "    cred_df = read_df(cred_path)\n",
    "    card_df = read_df(card_path)\n",
    "    cvas_df = read_df(cvas_path)\n",
    "\n",
    "    cred_df = cred_df.rename(columns={\n",
    "        'y_pred': 'y_pred_cred',\n",
    "        'y_score': 'y_score_cred',\n",
    "    })\n",
    "\n",
    "    card_df = card_df.rename(columns={\n",
    "        'y_pred': 'y_pred_card',\n",
    "        'y_score': 'y_score_card',\n",
    "    })\n",
    "\n",
    "    cvas_df = cvas_df.rename(columns={\n",
    "        'y_pred': 'y_pred_cvas',\n",
    "        'y_score': 'y_score_cvas',\n",
    "    })\n",
    "\n",
    "    merge_on = ['SMILES', 'Signature', 'Test_Fold', 'Model', 'Descriptors', 'y_true']\n",
    "\n",
    "    overlap_df = pd.merge(cred_df, card_df, on=merge_on, how='inner').merge(cvas_df, on=merge_on, how='inner')\n",
    "\n",
    "    cred_ddc = defaultdict(list)\n",
    "    card_ddc = defaultdict(list)\n",
    "    cvas_ddc = defaultdict(list)\n",
    "\n",
    "    for fold in overlap_df['Test_Fold'].unique():\n",
    "\n",
    "        sub_overlap_df = overlap_df[overlap_df['Test_Fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "        cred_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_cred'],\n",
    "            y_score=sub_overlap_df['y_score_cred']\n",
    "        )\n",
    "\n",
    "        card_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_card'],\n",
    "            y_score=sub_overlap_df['y_score_card']\n",
    "        )\n",
    "\n",
    "        cvas_score = inner_score(\n",
    "            y_true=sub_overlap_df['y_true'],\n",
    "            y_pred=sub_overlap_df['y_pred_cvas'],\n",
    "            y_score=sub_overlap_df['y_score_cvas']\n",
    "        )\n",
    "\n",
    "        for key, value in cred_score.items():\n",
    "            cred_ddc[key].append(value)\n",
    "\n",
    "        for key, value in card_score.items():\n",
    "            card_ddc[key].append(value)\n",
    "\n",
    "        for key, value in cvas_score.items():\n",
    "            cvas_ddc[key].append(value)\n",
    "\n",
    "        cred_ddc['Test_Fold'].append(fold)\n",
    "        card_ddc['Test_Fold'].append(fold)\n",
    "        cvas_ddc['Test_Fold'].append(fold)\n",
    "\n",
    "    cred_scores_df = pd.DataFrame(cred_ddc)\n",
    "    card_scores_df = pd.DataFrame(card_ddc)\n",
    "    cvas_scores_df = pd.DataFrame(cvas_ddc)\n",
    "\n",
    "    cred_scores_df['PT'] = 'Cred'\n",
    "    card_scores_df['PT'] = 'Card'\n",
    "    cvas_scores_df['PT'] = 'Cvas'\n",
    "\n",
    "    scores_df = pd.concat([cred_scores_df, card_scores_df, cvas_scores_df])\n",
    "    scores_df['Dataset'] = dataset.capitalize()\n",
    "    scores_df['DPA'] = dpa.upper()\n",
    "    scores_df['Model'] = model\n",
    "    scores_df['Descriptors'] = desc\n",
    "\n",
    "    melt_df = pd.melt(\n",
    "        frame=scores_df, id_vars=['Dataset', 'DPA', 'PT', 'Test_Fold', 'Model', 'Descriptors'],\n",
    "        value_vars=['Balanced Accuracy', 'GeomRS', 'HarmRS', 'F1 Score', 'ROC AUC', 'MCC', 'Accuracy', 'Recall', 'Specificity', 'Precision'],\n",
    "        var_name='Metric', value_name='Value')\n",
    "\n",
    "    out_dir = f'../results/comparison/cred_card_cvas'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_path = os.path.join(out_dir, f'{dataset}_{dpa}_{model}_{desc}_scores.tsv')\n",
    "    write_df(melt_df, out_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:11<00:00,  9.78it/s]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "5ca416cd22804243",
   "metadata": {},
   "source": [
    "Values for tables"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9c70c8f2c2e3a30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:39:33.406814Z",
     "start_time": "2026-01-21T12:39:33.319459Z"
    }
   },
   "source": [
    "dfs = []\n",
    "for file in glob.glob('../results/comparison/cred_card_cvas/*.tsv'):\n",
    "    dfs.append(read_df(file))\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "mean_df = df.groupby(by=['PT', 'Descriptors', 'Metric', 'Model'])['Value'].mean().reset_index(name='Mean')\n",
    "std_df = df.groupby(by=['PT', 'Descriptors', 'Metric', 'Model'])['Value'].std().reset_index(name='STD')\n",
    "\n",
    "comb_df = mean_df.merge(std_df, on=['PT', 'Descriptors', 'Metric', 'Model'])\n",
    "comb_df['Mean'] = comb_df['Mean'].apply(lambda value: np.round(value, 5))\n",
    "comb_df['STD'] = comb_df['STD'].apply(lambda value: np.round(value, 5))\n",
    "\n",
    "write_df(comb_df, '../results/comparison/pt_set_detailed.tsv')"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:39:43.455806Z",
     "start_time": "2026-01-21T12:39:43.383530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfs = []\n",
    "for file in glob.glob('../results/comparison/cred_card_cvas/*.tsv'):\n",
    "    dfs.append(read_df(file))\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "mean_df = df.groupby(by=['PT', 'Metric'])['Value'].mean().reset_index(name='Mean')\n",
    "std_df = df.groupby(by=['PT', 'Metric'])['Value'].std().reset_index(name='STD')\n",
    "\n",
    "comb_df = mean_df.merge(std_df, on=['PT', 'Metric'])\n",
    "comb_df['Mean'] = comb_df['Mean'].apply(lambda value: np.round(value, 5))\n",
    "comb_df['STD'] = comb_df['STD'].apply(lambda value: np.round(value, 5))\n",
    "\n",
    "write_df(comb_df, '../results/comparison/pt_set.tsv')"
   ],
   "id": "ba8741606ae7a71",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:39:46.343144Z",
     "start_time": "2026-01-21T12:39:46.290378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print as LaTeX rows\n",
    "df = read_df('../results/comparison/pt_set_detailed.tsv')\n",
    "\n",
    "for pt_set in ['Cred', 'Card', 'Cvas']:\n",
    "\n",
    "    ds_line = \"\\t\\multirow[t]{18}{*}{\" + pt_set + \"}\"\n",
    "    print(ds_line)\n",
    "\n",
    "    for model in ['LogisticRegression', 'RandomForestClassifier', 'XGBClassifier']:\n",
    "\n",
    "        ml_line = \"\\t\\t& \\multirow[t]{6}{*}{\" + model + \"}\"\n",
    "        print(ml_line)\n",
    "\n",
    "        sub_df = pl.from_pandas(df).filter((pl.col('PT') == pt_set) & (pl.col('Model') == model))\n",
    "        sub_df = sub_df.with_columns([\n",
    "            (pl.col('Mean') * 100).round(0).cast(pl.Int16).alias('Mean'),\n",
    "            (pl.col('STD') * 100).round(0).cast(pl.Int16).alias('STD'),\n",
    "        ])\n",
    "\n",
    "        for idx, desc in enumerate(['CDDD', 'ChemBERTa', 'Klek', 'MACCS', 'Morgan', 'RDKit']):\n",
    "            metrics = sub_df.filter(pl.col('Descriptors') == desc)\n",
    "            rc_mean = metrics.filter(pl.col('Metric') == 'Recall')['Mean'].item()\n",
    "            rc_std = metrics.filter(pl.col('Metric') == 'Recall')['STD'].item()\n",
    "            sp_mean = metrics.filter(pl.col('Metric') == 'Specificity')['Mean'].item()\n",
    "            sp_std = metrics.filter(pl.col('Metric') == 'Specificity')['STD'].item()\n",
    "            roc_mean = metrics.filter(pl.col('Metric') == 'ROC AUC')['Mean'].item()\n",
    "            roc_std = metrics.filter(pl.col('Metric') == 'ROC AUC')['STD'].item()\n",
    "            harm_mean = metrics.filter(pl.col('Metric') == 'HarmRS')['Mean'].item()\n",
    "            harm_std = metrics.filter(pl.col('Metric') == 'HarmRS')['STD'].item()\n",
    "\n",
    "            if idx == 0:\n",
    "                pre = \"  &\"\n",
    "            else:\n",
    "                pre = \"& &\"\n",
    "\n",
    "            empty_lines = \" \" * (9 - len(desc))\n",
    "\n",
    "            line = f\"\\t\\t\\t{pre} {desc} {empty_lines}& {rc_mean} ± {rc_std} & {sp_mean} ± {sp_std} & {roc_mean} ± {roc_std} & {harm_mean} ± {harm_std} \\\\\\\\\"\n",
    "            print(line)"
   ],
   "id": "f32e7d459eab67fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\\multirow[t]{18}{*}{Cred}\n",
      "\t\t& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "\t\t\t  & CDDD      & 57 ± 8 & 51 ± 10 & 56 ± 3 & 52 ± 4 \\\\\n",
      "\t\t\t& & ChemBERTa & 53 ± 8 & 50 ± 8 & 52 ± 4 & 50 ± 3 \\\\\n",
      "\t\t\t& & Klek      & 56 ± 8 & 55 ± 9 & 57 ± 5 & 54 ± 4 \\\\\n",
      "\t\t\t& & MACCS     & 55 ± 18 & 54 ± 18 & 57 ± 3 & 49 ± 6 \\\\\n",
      "\t\t\t& & Morgan    & 59 ± 10 & 54 ± 11 & 59 ± 4 & 55 ± 4 \\\\\n",
      "\t\t\t& & RDKit     & 55 ± 17 & 57 ± 17 & 59 ± 3 & 51 ± 6 \\\\\n",
      "\t\t& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "\t\t\t  & CDDD      & 66 ± 15 & 45 ± 18 & 61 ± 3 & 49 ± 12 \\\\\n",
      "\t\t\t& & ChemBERTa & 67 ± 15 & 41 ± 15 & 57 ± 4 & 47 ± 10 \\\\\n",
      "\t\t\t& & Klek      & 59 ± 19 & 54 ± 20 & 61 ± 3 & 50 ± 10 \\\\\n",
      "\t\t\t& & MACCS     & 63 ± 12 & 50 ± 13 & 61 ± 4 & 54 ± 6 \\\\\n",
      "\t\t\t& & Morgan    & 58 ± 21 & 55 ± 22 & 61 ± 3 & 49 ± 10 \\\\\n",
      "\t\t\t& & RDKit     & 66 ± 12 & 47 ± 12 & 61 ± 4 & 52 ± 7 \\\\\n",
      "\t\t& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "\t\t\t  & CDDD      & 64 ± 12 & 50 ± 15 & 61 ± 3 & 53 ± 7 \\\\\n",
      "\t\t\t& & ChemBERTa & 63 ± 13 & 46 ± 14 & 58 ± 3 & 50 ± 7 \\\\\n",
      "\t\t\t& & Klek      & 61 ± 14 & 54 ± 15 & 61 ± 4 & 54 ± 7 \\\\\n",
      "\t\t\t& & MACCS     & 62 ± 13 & 53 ± 14 & 61 ± 4 & 54 ± 5 \\\\\n",
      "\t\t\t& & Morgan    & 61 ± 14 & 54 ± 15 & 62 ± 3 & 54 ± 6 \\\\\n",
      "\t\t\t& & RDKit     & 62 ± 13 & 53 ± 13 & 62 ± 4 & 55 ± 5 \\\\\n",
      "\t\\multirow[t]{18}{*}{Card}\n",
      "\t\t& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "\t\t\t  & CDDD      & 58 ± 9 & 50 ± 10 & 56 ± 3 & 52 ± 3 \\\\\n",
      "\t\t\t& & ChemBERTa & 54 ± 8 & 48 ± 7 & 52 ± 3 & 50 ± 3 \\\\\n",
      "\t\t\t& & Klek      & 58 ± 10 & 54 ± 10 & 58 ± 4 & 54 ± 4 \\\\\n",
      "\t\t\t& & MACCS     & 57 ± 18 & 53 ± 18 & 57 ± 3 & 49 ± 7 \\\\\n",
      "\t\t\t& & Morgan    & 61 ± 9 & 52 ± 11 & 59 ± 4 & 54 ± 4 \\\\\n",
      "\t\t\t& & RDKit     & 57 ± 17 & 56 ± 17 & 59 ± 3 & 51 ± 6 \\\\\n",
      "\t\t& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "\t\t\t  & CDDD      & 67 ± 15 & 44 ± 18 & 61 ± 3 & 48 ± 12 \\\\\n",
      "\t\t\t& & ChemBERTa & 66 ± 16 & 41 ± 16 & 57 ± 4 & 46 ± 11 \\\\\n",
      "\t\t\t& & Klek      & 61 ± 20 & 51 ± 22 & 61 ± 3 & 48 ± 11 \\\\\n",
      "\t\t\t& & MACCS     & 67 ± 12 & 47 ± 13 & 61 ± 4 & 52 ± 7 \\\\\n",
      "\t\t\t& & Morgan    & 62 ± 19 & 52 ± 22 & 62 ± 3 & 49 ± 11 \\\\\n",
      "\t\t\t& & RDKit     & 67 ± 14 & 45 ± 13 & 60 ± 4 & 51 ± 8 \\\\\n",
      "\t\t& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "\t\t\t  & CDDD      & 66 ± 12 & 47 ± 14 & 61 ± 3 & 52 ± 7 \\\\\n",
      "\t\t\t& & ChemBERTa & 64 ± 13 & 45 ± 14 & 58 ± 3 & 49 ± 7 \\\\\n",
      "\t\t\t& & Klek      & 63 ± 13 & 51 ± 15 & 61 ± 4 & 53 ± 7 \\\\\n",
      "\t\t\t& & MACCS     & 62 ± 14 & 53 ± 15 & 62 ± 3 & 54 ± 5 \\\\\n",
      "\t\t\t& & Morgan    & 64 ± 14 & 52 ± 15 & 62 ± 3 & 54 ± 7 \\\\\n",
      "\t\t\t& & RDKit     & 64 ± 12 & 51 ± 12 & 62 ± 4 & 54 ± 6 \\\\\n",
      "\t\\multirow[t]{18}{*}{Cvas}\n",
      "\t\t& \\multirow[t]{6}{*}{LogisticRegression}\n",
      "\t\t\t  & CDDD      & 57 ± 10 & 52 ± 9 & 57 ± 3 & 53 ± 3 \\\\\n",
      "\t\t\t& & ChemBERTa & 55 ± 9 & 49 ± 8 & 53 ± 3 & 51 ± 3 \\\\\n",
      "\t\t\t& & Klek      & 58 ± 10 & 54 ± 8 & 58 ± 3 & 54 ± 3 \\\\\n",
      "\t\t\t& & MACCS     & 54 ± 19 & 55 ± 18 & 57 ± 4 & 48 ± 7 \\\\\n",
      "\t\t\t& & Morgan    & 60 ± 9 & 51 ± 10 & 58 ± 4 & 54 ± 4 \\\\\n",
      "\t\t\t& & RDKit     & 55 ± 18 & 57 ± 16 & 59 ± 4 & 51 ± 6 \\\\\n",
      "\t\t& \\multirow[t]{6}{*}{RandomForestClassifier}\n",
      "\t\t\t  & CDDD      & 71 ± 15 & 42 ± 17 & 61 ± 3 & 48 ± 12 \\\\\n",
      "\t\t\t& & ChemBERTa & 68 ± 14 & 41 ± 15 & 58 ± 4 & 47 ± 10 \\\\\n",
      "\t\t\t& & Klek      & 55 ± 25 & 55 ± 25 & 60 ± 4 & 43 ± 15 \\\\\n",
      "\t\t\t& & MACCS     & 65 ± 12 & 48 ± 13 & 61 ± 3 & 52 ± 6 \\\\\n",
      "\t\t\t& & Morgan    & 55 ± 21 & 57 ± 22 & 60 ± 3 & 48 ± 11 \\\\\n",
      "\t\t\t& & RDKit     & 69 ± 13 & 45 ± 13 & 62 ± 3 & 52 ± 7 \\\\\n",
      "\t\t& \\multirow[t]{6}{*}{XGBClassifier}\n",
      "\t\t\t  & CDDD      & 64 ± 11 & 50 ± 13 & 61 ± 2 & 54 ± 5 \\\\\n",
      "\t\t\t& & ChemBERTa & 63 ± 12 & 46 ± 12 & 58 ± 3 & 51 ± 6 \\\\\n",
      "\t\t\t& & Klek      & 59 ± 16 & 54 ± 16 & 60 ± 4 & 52 ± 6 \\\\\n",
      "\t\t\t& & MACCS     & 60 ± 15 & 55 ± 14 & 62 ± 4 & 54 ± 5 \\\\\n",
      "\t\t\t& & Morgan    & 63 ± 14 & 52 ± 15 & 61 ± 3 & 53 ± 6 \\\\\n",
      "\t\t\t& & RDKit     & 62 ± 12 & 52 ± 13 & 61 ± 3 & 54 ± 5 \\\\\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Statistical Tests",
   "id": "dd160a9465ce3071"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Primary vs Secondary",
   "id": "610bde7d12e8a7cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T13:40:13.014748Z",
     "start_time": "2026-01-26T13:40:13.012456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sign_level = 0.01\n",
    "metrics = ['HarmRS', 'ROC AUC']"
   ],
   "id": "583a4f760506d136",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T14:14:12.794358Z",
     "start_time": "2026-01-22T14:14:12.497428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "group_col = 'Dataset'\n",
    "pairs = [('Primary', 'Secondary')]\n",
    "index_cols = ['Model', 'Descriptors', 'Fold', 'PT', 'DPA']\n",
    "\n",
    "for metric in metrics:\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for file in glob.glob('../results/comparison/primary_secondary/*.tsv'):\n",
    "        _, _, _, _, file_name = file.split('.')[2].split('/')\n",
    "        pt_set, dpa_metric, model, descriptors, _ = file_name.split('_')\n",
    "        df = (pl.from_pandas(read_df(file))\n",
    "                .filter(pl.col('Metric') == metric)\n",
    "                .rename({'Value': metric, 'Test_Fold': 'Fold'})\n",
    "                .cast({'Fold': pl.String})\n",
    "                .drop('Metric')\n",
    "        )\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pl.concat(dfs)\n",
    "\n",
    "    ds_df = compare_pairs(df, group_col=group_col, pairs=pairs, index_cols=index_cols,\n",
    "                          sign_level=sign_level)\n",
    "\n",
    "    print(f'< {metric} >')\n",
    "    print(ds_df)\n",
    "\n",
    "    ds_df = ds_df.to_pandas()\n",
    "    ds_df.insert(loc=0, column='metric', value=([metric]*len(pairs)))\n",
    "\n",
    "    write_df(ds_df, f'../results/analysis/wilcox/dataset_type_{metric}.tsv')"
   ],
   "id": "157bbba0d2f6a9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< HarmRS >\n",
      "shape: (1, 7)\n",
      "┌──────────────────────┬───────────────┬───────────┬─────────────┬─────────┬────────────┬──────────┐\n",
      "│ null_hypothesis      ┆ null_rejected ┆ outcome   ┆ effect_size ┆ w_stat  ┆ p_value    ┆ r_stat   │\n",
      "│ ---                  ┆ ---           ┆ ---       ┆ ---         ┆ ---     ┆ ---        ┆ ---      │\n",
      "│ str                  ┆ bool          ┆ str       ┆ str         ┆ f64     ┆ f64        ┆ f64      │\n",
      "╞══════════════════════╪═══════════════╪═══════════╪═════════════╪═════════╪════════════╪══════════╡\n",
      "│ Primary == Secondary ┆ true          ┆ Primary > ┆ Large       ┆ 69897.0 ┆ 1.5844e-45 ┆ 0.574389 │\n",
      "│                      ┆               ┆ Secondary ┆             ┆         ┆            ┆          │\n",
      "└──────────────────────┴───────────────┴───────────┴─────────────┴─────────┴────────────┴──────────┘\n",
      "< ROC AUC >\n",
      "shape: (1, 7)\n",
      "┌────────────────────────┬───────────────┬───────────┬─────────────┬──────────┬─────────┬──────────┐\n",
      "│ null_hypothesis        ┆ null_rejected ┆ outcome   ┆ effect_size ┆ w_stat   ┆ p_value ┆ r_stat   │\n",
      "│ ---                    ┆ ---           ┆ ---       ┆ ---         ┆ ---      ┆ ---     ┆ ---      │\n",
      "│ str                    ┆ bool          ┆ str       ┆ str         ┆ f64      ┆ f64     ┆ f64      │\n",
      "╞════════════════════════╪═══════════════╪═══════════╪═════════════╪══════════╪═════════╪══════════╡\n",
      "│ Primary == Secondary   ┆ true          ┆ Primary > ┆ Small       ┆ 142589.0 ┆ 0.00116 ┆ 0.131759 │\n",
      "│                        ┆               ┆ Secondary ┆             ┆          ┆         ┆          │\n",
      "└────────────────────────┴───────────────┴───────────┴─────────────┴──────────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cred vs Card vs Cvas",
   "id": "edeb9c4d288d9054"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T14:13:29.391695Z",
     "start_time": "2026-01-22T14:13:29.179767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "group_col = 'PT'\n",
    "pairs = [('Cred', 'Card'), ('Cred', 'Cvas'), ('Card', 'Cvas')]\n",
    "index_cols = ['Model', 'Descriptors', 'Fold', 'Dataset', 'DPA']\n",
    "\n",
    "for metric in metrics:\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for file in glob.glob('../results/comparison/cred_card_cvas/*.tsv'):\n",
    "        _, _, _, _, file_name = file.split('.')[2].split('/')\n",
    "        dataset_type, dpa_metric, model, descriptors, _ = file_name.split('_')\n",
    "        df = (pl.from_pandas(read_df(file))\n",
    "                .filter(pl.col('Metric') == metric)\n",
    "                .rename({'Value': metric, 'Test_Fold': 'Fold'})\n",
    "                .cast({'Fold': pl.String})\n",
    "                .drop('Metric')\n",
    "        )\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pl.concat(dfs)\n",
    "\n",
    "    pt_df = compare_pairs(df, group_col=group_col, pairs=pairs, index_cols=index_cols,\n",
    "                      sign_level=sign_level)\n",
    "\n",
    "    print(f'< {metric} >')\n",
    "    print(pt_df)\n",
    "\n",
    "    pt_df = pt_df.to_pandas()\n",
    "    pt_df.insert(loc=0, column='metric', value=([metric]*len(pairs)))\n",
    "\n",
    "    write_df(pt_df, f'../results/analysis/wilcox/pt_set_{metric}.tsv')"
   ],
   "id": "bf9350beb02e7718",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< HarmRS >\n",
      "   metric null_hypothesis  null_rejected       outcome effect_size   w_stat  \\\n",
      "0  HarmRS    Cred == Card           True   Cred > Card       Small  59998.0   \n",
      "1  HarmRS    Cred == Cvas          False  Cred == Cvas       Small  64303.0   \n",
      "2  HarmRS    Card == Cvas          False  Card == Cvas  Negligible  71857.5   \n",
      "\n",
      "    p_value    r_stat  \n",
      "0  0.000326  0.178503  \n",
      "1  0.016082  0.119559  \n",
      "2  0.745583 -0.016122  \n",
      "< ROC AUC >\n",
      "    metric null_hypothesis  null_rejected       outcome effect_size   w_stat  \\\n",
      "0  ROC AUC    Cred == Card          False  Cred == Card  Negligible  69957.5   \n",
      "1  ROC AUC    Cred == Cvas          False  Cred == Cvas  Negligible  71528.5   \n",
      "2  ROC AUC    Card == Cvas          False  Card == Cvas  Negligible  69997.5   \n",
      "\n",
      "    p_value    r_stat  \n",
      "0  0.396298 -0.042137  \n",
      "1  0.732590  0.016993  \n",
      "2  0.402466  0.041590  \n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PRR vs ROR vs IC",
   "id": "d3b007ba5179a063"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T13:40:16.881005Z",
     "start_time": "2026-01-26T13:40:16.643326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "group_col = 'DPA'\n",
    "pairs = [('PRR', 'ROR'), ('PRR', 'IC'), ('ROR', 'IC')]\n",
    "index_cols = ['Model', 'Descriptors', 'Fold', 'Dataset', 'PT']\n",
    "\n",
    "for metric in metrics:\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for file in glob.glob('../results/comparison/prr_ror_ic/*.tsv'):\n",
    "        _, _, _, _, file_name = file.split('.')[2].split('/')\n",
    "        dataset_type, pt_set, model, descriptors, _ = file_name.split('_')\n",
    "        df = (pl.from_pandas(read_df(file))\n",
    "                .filter(pl.col('Metric') == metric)\n",
    "                .rename({'Value': metric, 'Test_Fold': 'Fold'})\n",
    "                .cast({'Fold': pl.String})\n",
    "                .drop('Metric')\n",
    "        )\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pl.concat(dfs)\n",
    "\n",
    "    dpa_df = compare_pairs(df, group_col=group_col, pairs=pairs, index_cols=index_cols, sign_level=sign_level)\n",
    "\n",
    "    print(f'< {metric} >')\n",
    "    print(dpa_df)\n",
    "\n",
    "    dpa_df = dpa_df.to_pandas()\n",
    "    dpa_df.insert(loc=0, column='metric', value=([metric]*len(pairs)))\n",
    "\n",
    "    #write_df(dpa_df, f'../results/analysis/wilcox/dpa_metric_{metric}.tsv')"
   ],
   "id": "3f2708805d420b93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< HarmRS >\n",
      "shape: (3, 7)\n",
      "┌─────────────────┬───────────────┬───────────┬─────────────┬─────────┬────────────┬──────────┐\n",
      "│ null_hypothesis ┆ null_rejected ┆ outcome   ┆ effect_size ┆ w_stat  ┆ p_value    ┆ r_stat   │\n",
      "│ ---             ┆ ---           ┆ ---       ┆ ---         ┆ ---     ┆ ---        ┆ ---      │\n",
      "│ str             ┆ bool          ┆ str       ┆ str         ┆ f64     ┆ f64        ┆ f64      │\n",
      "╞═════════════════╪═══════════════╪═══════════╪═════════════╪═════════╪════════════╪══════════╡\n",
      "│ PRR == ROR      ┆ true          ┆ PRR > ROR ┆ Medium      ┆ 39469.5 ┆ 3.4445e-20 ┆ 0.457576 │\n",
      "│ PRR == IC       ┆ true          ┆ PRR > IC  ┆ Large       ┆ 3193.0  ┆ 1.3181e-82 ┆ 0.956281 │\n",
      "│ ROR == IC       ┆ true          ┆ ROR > IC  ┆ Large       ┆ 15298.0 ┆ 4.8682e-57 ┆ 0.790539 │\n",
      "└─────────────────┴───────────────┴───────────┴─────────────┴─────────┴────────────┴──────────┘\n",
      "< ROC AUC >\n",
      "shape: (3, 7)\n",
      "┌─────────────────┬───────────────┬───────────┬─────────────┬─────────┬────────────┬──────────┐\n",
      "│ null_hypothesis ┆ null_rejected ┆ outcome   ┆ effect_size ┆ w_stat  ┆ p_value    ┆ r_stat   │\n",
      "│ ---             ┆ ---           ┆ ---       ┆ ---         ┆ ---     ┆ ---        ┆ ---      │\n",
      "│ str             ┆ bool          ┆ str       ┆ str         ┆ f64     ┆ f64        ┆ f64      │\n",
      "╞═════════════════╪═══════════════╪═══════════╪═════════════╪═════════╪════════════╪══════════╡\n",
      "│ PRR == ROR      ┆ true          ┆ PRR > ROR ┆ Medium      ┆ 45078.0 ┆ 1.2890e-14 ┆ 0.382789 │\n",
      "│ PRR == IC       ┆ false         ┆ PRR == IC ┆ Negligible  ┆ 71078.5 ┆ 0.641158   ┆ 0.023177 │\n",
      "│ ROR == IC       ┆ true          ┆ ROR < IC  ┆ Medium      ┆ 44323.0 ┆ 5.7360e-15 ┆ -0.38861 │\n",
      "└─────────────────┴───────────────┴───────────┴─────────────┴─────────┴────────────┴──────────┘\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Holm correction",
   "id": "3ca0e6b99967f12f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T14:16:51.542183Z",
     "start_time": "2026-01-22T14:16:51.472681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "dfs = pl.concat([pl.DataFrame(read_df(file)) for file in glob.glob('../results/analysis/wilcox/*.tsv')])\n",
    "dfs = dfs.sort('p_value')\n",
    "\n",
    "rejected, p_adjusted, _, _ = multipletests(\n",
    "    dfs['p_value'].to_numpy(),\n",
    "    alpha=sign_level,\n",
    "    method='holm',\n",
    "    is_sorted=True\n",
    ")\n",
    "\n",
    "dfs = dfs.with_columns([\n",
    "    pl.Series('p_value_adj', p_adjusted),\n",
    "    pl.Series('null_rejected_adj', rejected),\n",
    "])\n",
    "\n",
    "write_df(dfs.to_pandas(), '../results/analysis/holm_correction.tsv')\n",
    "dfs"
   ],
   "id": "67dcbc1c5addd5bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (14, 10)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ metric  ┆ null_hypot ┆ null_reje ┆ outcome   ┆ … ┆ p_value   ┆ r_stat    ┆ p_value_a ┆ null_reje │\n",
       "│ ---     ┆ hesis      ┆ cted      ┆ ---       ┆   ┆ ---       ┆ ---       ┆ dj        ┆ cted_adj  │\n",
       "│ str     ┆ ---        ┆ ---       ┆ str       ┆   ┆ f64       ┆ f64       ┆ ---       ┆ ---       │\n",
       "│         ┆ str        ┆ bool      ┆           ┆   ┆           ┆           ┆ f64       ┆ bool      │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ HarmRS  ┆ PRR == IC  ┆ true      ┆ PRR > IC  ┆ … ┆ 1.3181e-8 ┆ 0.956281  ┆ 1.8454e-8 ┆ true      │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 2         ┆           ┆ 1         ┆           │\n",
       "│ HarmRS  ┆ ROR == IC  ┆ true      ┆ ROR > IC  ┆ … ┆ 4.8682e-5 ┆ 0.790539  ┆ 6.3286e-5 ┆ true      │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 7         ┆           ┆ 6         ┆           │\n",
       "│ HarmRS  ┆ Primary == ┆ true      ┆ Primary > ┆ … ┆ 1.5844e-4 ┆ 0.574389  ┆ 1.9013e-4 ┆ true      │\n",
       "│         ┆ Secondary  ┆           ┆ Secondary ┆   ┆ 5         ┆           ┆ 4         ┆           │\n",
       "│ HarmRS  ┆ PRR == ROR ┆ true      ┆ PRR > ROR ┆ … ┆ 3.4445e-2 ┆ 0.457576  ┆ 3.7890e-1 ┆ true      │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 0         ┆           ┆ 9         ┆           │\n",
       "│ ROC AUC ┆ ROR == IC  ┆ true      ┆ ROR < IC  ┆ … ┆ 5.7360e-1 ┆ -0.38861  ┆ 5.7360e-1 ┆ true      │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 5         ┆           ┆ 4         ┆           │\n",
       "│ …       ┆ …          ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ ROC AUC ┆ Cred ==    ┆ false     ┆ Cred ==   ┆ … ┆ 0.396298  ┆ -0.042137 ┆ 1.0       ┆ false     │\n",
       "│         ┆ Card       ┆           ┆ Card      ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ROC AUC ┆ Card ==    ┆ false     ┆ Card ==   ┆ … ┆ 0.402466  ┆ 0.04159   ┆ 1.0       ┆ false     │\n",
       "│         ┆ Cvas       ┆           ┆ Cvas      ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ROC AUC ┆ PRR == IC  ┆ false     ┆ PRR == IC ┆ … ┆ 0.641158  ┆ 0.023177  ┆ 1.0       ┆ false     │\n",
       "│ ROC AUC ┆ Cred ==    ┆ false     ┆ Cred ==   ┆ … ┆ 0.73259   ┆ 0.016993  ┆ 1.0       ┆ false     │\n",
       "│         ┆ Cvas       ┆           ┆ Cvas      ┆   ┆           ┆           ┆           ┆           │\n",
       "│ HarmRS  ┆ Card ==    ┆ false     ┆ Card ==   ┆ … ┆ 0.745583  ┆ -0.016122 ┆ 1.0       ┆ false     │\n",
       "│         ┆ Cvas       ┆           ┆ Cvas      ┆   ┆           ┆           ┆           ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (14, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>metric</th><th>null_hypothesis</th><th>null_rejected</th><th>outcome</th><th>effect_size</th><th>w_stat</th><th>p_value</th><th>r_stat</th><th>p_value_adj</th><th>null_rejected_adj</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>bool</td></tr></thead><tbody><tr><td>&quot;HarmRS&quot;</td><td>&quot;PRR == IC&quot;</td><td>true</td><td>&quot;PRR &gt; IC&quot;</td><td>&quot;Large&quot;</td><td>3193.0</td><td>1.3181e-82</td><td>0.956281</td><td>1.8454e-81</td><td>true</td></tr><tr><td>&quot;HarmRS&quot;</td><td>&quot;ROR == IC&quot;</td><td>true</td><td>&quot;ROR &gt; IC&quot;</td><td>&quot;Large&quot;</td><td>15298.0</td><td>4.8682e-57</td><td>0.790539</td><td>6.3286e-56</td><td>true</td></tr><tr><td>&quot;HarmRS&quot;</td><td>&quot;Primary == Secondary&quot;</td><td>true</td><td>&quot;Primary &gt; Secondary&quot;</td><td>&quot;Large&quot;</td><td>69897.0</td><td>1.5844e-45</td><td>0.574389</td><td>1.9013e-44</td><td>true</td></tr><tr><td>&quot;HarmRS&quot;</td><td>&quot;PRR == ROR&quot;</td><td>true</td><td>&quot;PRR &gt; ROR&quot;</td><td>&quot;Medium&quot;</td><td>39469.5</td><td>3.4445e-20</td><td>0.457576</td><td>3.7890e-19</td><td>true</td></tr><tr><td>&quot;ROC AUC&quot;</td><td>&quot;ROR == IC&quot;</td><td>true</td><td>&quot;ROR &lt; IC&quot;</td><td>&quot;Medium&quot;</td><td>44323.0</td><td>5.7360e-15</td><td>-0.38861</td><td>5.7360e-14</td><td>true</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;ROC AUC&quot;</td><td>&quot;Cred == Card&quot;</td><td>false</td><td>&quot;Cred == Card&quot;</td><td>&quot;Negligible&quot;</td><td>69957.5</td><td>0.396298</td><td>-0.042137</td><td>1.0</td><td>false</td></tr><tr><td>&quot;ROC AUC&quot;</td><td>&quot;Card == Cvas&quot;</td><td>false</td><td>&quot;Card == Cvas&quot;</td><td>&quot;Negligible&quot;</td><td>69997.5</td><td>0.402466</td><td>0.04159</td><td>1.0</td><td>false</td></tr><tr><td>&quot;ROC AUC&quot;</td><td>&quot;PRR == IC&quot;</td><td>false</td><td>&quot;PRR == IC&quot;</td><td>&quot;Negligible&quot;</td><td>71078.5</td><td>0.641158</td><td>0.023177</td><td>1.0</td><td>false</td></tr><tr><td>&quot;ROC AUC&quot;</td><td>&quot;Cred == Cvas&quot;</td><td>false</td><td>&quot;Cred == Cvas&quot;</td><td>&quot;Negligible&quot;</td><td>71528.5</td><td>0.73259</td><td>0.016993</td><td>1.0</td><td>false</td></tr><tr><td>&quot;HarmRS&quot;</td><td>&quot;Card == Cvas&quot;</td><td>false</td><td>&quot;Card == Cvas&quot;</td><td>&quot;Negligible&quot;</td><td>71857.5</td><td>0.745583</td><td>-0.016122</td><td>1.0</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:13:31.736318Z",
     "start_time": "2026-01-22T15:13:31.731575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LaTeX table\n",
    "df = pl.from_pandas(read_df('../results/analysis/holm_correction.tsv'))\n",
    "\n",
    "for metric in ['HarmRS', 'ROC AUC']:\n",
    "    header_line = '\\t\\multicolumn{7}{*}{' + f\"{metric}\" + \"} \\\\\\\\\"\n",
    "    print(header_line)\n",
    "    sub_df = df.filter(pl.col('metric') == metric).drop('metric')\n",
    "    for row in sub_df.iter_rows():\n",
    "        null_hp, _, outcome, effect_size, w_stat, p_val, r_stat, p_val_adj, _ = row\n",
    "        null_hp = null_hp.replace('==', '$\\sim$')\n",
    "        outcome = outcome.replace('==', '$\\sim$')\n",
    "        empty_lines = \" \" * (24 - len(null_hp))\n",
    "\n",
    "        p_val = round_to_significant(p_val, 3)\n",
    "        r_stat = round_to_significant(r_stat, 3)\n",
    "        p_val_adj = round_to_significant(p_val_adj, 3)\n",
    "\n",
    "        line = f\"\\t\\t{null_hp} {empty_lines}& {int(w_stat)} & {p_val} & {r_stat} & {effect_size} & {p_val_adj} & {outcome} \\\\\\\\\"\n",
    "        print(line)"
   ],
   "id": "fee189670df9c87b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\\multicolumn{7}{*}{HarmRS} \\\\\n",
      "\t\tPRR $\\sim$ IC            & 3193 & 1.32e-82 & 0.956 & Large & 1.85e-81 & PRR > IC \\\\\n",
      "\t\tROR $\\sim$ IC            & 15298 & 4.87e-57 & 0.791 & Large & 6.33e-56 & ROR > IC \\\\\n",
      "\t\tPrimary $\\sim$ Secondary & 69897 & 1.58e-45 & 0.574 & Large & 1.9e-44 & Primary > Secondary \\\\\n",
      "\t\tPRR $\\sim$ ROR           & 39469 & 3.44e-20 & 0.458 & Medium & 3.79e-19 & PRR > ROR \\\\\n",
      "\t\tCred $\\sim$ Card         & 59998 & 0.000326 & 0.179 & Small & 0.00261 & Cred > Card \\\\\n",
      "\t\tCred $\\sim$ Cvas         & 64303 & 0.0161 & 0.12 & Small & 0.0965 & Cred $\\sim$ Cvas \\\\\n",
      "\t\tCard $\\sim$ Cvas         & 71857 & 0.746 & -0.0161 & Negligible & 1.0 & Card $\\sim$ Cvas \\\\\n",
      "\t\\multicolumn{7}{*}{ROC AUC} \\\\\n",
      "\t\tROR $\\sim$ IC            & 44323 & 5.74e-15 & -0.389 & Medium & 5.74e-14 & ROR < IC \\\\\n",
      "\t\tPRR $\\sim$ ROR           & 45078 & 1.29e-14 & 0.383 & Medium & 1.16e-13 & PRR > ROR \\\\\n",
      "\t\tPrimary $\\sim$ Secondary & 142589 & 0.00116 & 0.132 & Small & 0.00812 & Primary > Secondary \\\\\n",
      "\t\tCred $\\sim$ Card         & 69957 & 0.396 & -0.0421 & Negligible & 1.0 & Cred $\\sim$ Card \\\\\n",
      "\t\tCard $\\sim$ Cvas         & 69997 & 0.402 & 0.0416 & Negligible & 1.0 & Card $\\sim$ Cvas \\\\\n",
      "\t\tPRR $\\sim$ IC            & 71078 & 0.641 & 0.0232 & Negligible & 1.0 & PRR $\\sim$ IC \\\\\n",
      "\t\tCred $\\sim$ Cvas         & 71528 & 0.733 & 0.017 & Negligible & 1.0 & Cred $\\sim$ Cvas \\\\\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "id": "3373a0ad-dd52-4425-bc86-e51aa9dedc24",
   "metadata": {},
   "source": "### Models' results on the selected variant"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:00:27.473928Z",
     "start_time": "2026-01-19T13:00:27.439762Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 44,
   "source": [
    "# Aggregate results on Primary-PRR-Cred variant\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in glob.glob('../results/aggregated/primary_Cred_prr/*scores.tsv'):\n",
    "    df = read_df(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs).reset_index(drop=True)"
   ],
   "id": "99ce2d25-4d08-4f14-bfbf-e32a8c84929e"
  },
  {
   "cell_type": "code",
   "id": "02a9b7ab-7102-4f8f-af09-db1b25bdde06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:00:30.695581Z",
     "start_time": "2026-01-19T13:00:30.498175Z"
    }
   },
   "source": [
    "total_df = df[df['Kind'] == 'Total | Total']\n",
    "sex_df = df[['Sex' in row['Kind'] for idx, row in df.iterrows()]].reset_index(drop=True)\n",
    "age_df = df[['Age' in row['Kind'] for idx, row in df.iterrows()]].reset_index(drop=True)\n",
    "wgt_df = df[['Weight' in row['Kind'] for idx, row in df.iterrows()]].reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "a783e3ff-6733-415e-8b1a-4624488d7da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:00:33.671239Z",
     "start_time": "2026-01-19T13:00:33.661750Z"
    }
   },
   "source": [
    "total_df = total_df.drop(columns=['TP', 'FP', 'FN', 'TN', 'Accuracy', 'Precision', 'Balanced Accuracy', 'GeomRS', 'F1 Score', 'Kind', 'MCC'])\n",
    "total_df = pd.melt(total_df, id_vars=['Series', 'Test_Fold', 'Model', 'Descriptors'], value_vars=['Recall', 'Specificity', 'HarmRS', 'ROC AUC'], \n",
    "                   var_name='Metric', value_name='Value')\n",
    "write_df(total_df, '../results/analysis/total.tsv')"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "d0eb1e4a-e28d-4e81-8cb0-2d2b16e6c307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:00:36.653772Z",
     "start_time": "2026-01-19T13:00:36.637534Z"
    }
   },
   "source": [
    "sex_df.loc[:, 'Sex'] = sex_df['Kind'].apply(lambda desc: desc.split(' | ')[-1])\n",
    "sex_df = sex_df.drop(columns=['TP', 'FP', 'FN', 'TN', 'Accuracy', 'Precision', 'Balanced Accuracy', 'GeomRS', 'F1 Score', 'Kind', 'MCC'])\n",
    "sex_df = pd.melt(sex_df, id_vars=['Series', 'Test_Fold', 'Model', 'Descriptors', 'Sex'], value_vars=['Recall', 'Specificity', 'HarmRS', 'ROC AUC'], \n",
    "                   var_name='Metric', value_name='Value')\n",
    "write_df(sex_df, '../results/analysis/sex.tsv')"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "a53f91c9-331a-4456-a8df-7f7f847ddf2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:00:39.672456Z",
     "start_time": "2026-01-19T13:00:39.650743Z"
    }
   },
   "source": [
    "age_df.loc[:, 'Age'] = age_df['Kind'].apply(lambda desc: desc.split(' | ')[-1])\n",
    "age_df = age_df.drop(columns=['TP', 'FP', 'FN', 'TN', 'Accuracy', 'Precision', 'Balanced Accuracy', 'GeomRS', 'F1 Score', 'Kind', 'MCC'])\n",
    "age_df = pd.melt(age_df, id_vars=['Series', 'Test_Fold', 'Model', 'Descriptors', 'Age'], value_vars=['Recall', 'Specificity', 'HarmRS', 'ROC AUC'], \n",
    "                   var_name='Metric', value_name='Value')\n",
    "write_df(age_df, '../results/analysis/age.tsv')"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "5a43e215-c1fc-4c37-aa84-bcc9f4327b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:00:40.356835Z",
     "start_time": "2026-01-19T13:00:40.338428Z"
    }
   },
   "source": [
    "wgt_df.loc[:, 'Weight'] = wgt_df['Kind'].apply(lambda desc: desc.split(' | ')[-1])\n",
    "wgt_df = wgt_df.drop(columns=['TP', 'FP', 'FN', 'TN', 'Accuracy', 'Precision', 'Balanced Accuracy', 'GeomRS', 'F1 Score', 'Kind', 'MCC'])\n",
    "wgt_df = pd.melt(wgt_df, id_vars=['Series', 'Test_Fold', 'Model', 'Descriptors', 'Weight'], value_vars=['Recall', 'Specificity', 'HarmRS', 'ROC AUC'], \n",
    "                   var_name='Metric', value_name='Value')\n",
    "write_df(wgt_df, '../results/analysis/weight.tsv')"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset characteristics",
   "id": "a21ded821a8870b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T10:39:16.218384Z",
     "start_time": "2026-01-19T10:39:07.004070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Characterize all dataset variants\n",
    "\n",
    "os.makedirs('../results/analysis/', exist_ok=True)\n",
    "\n",
    "prms_df = []\n",
    "\n",
    "dataset_dtype = pd.CategoricalDtype(categories=['Primary', 'Secondary'], ordered=True)\n",
    "pt_dtype = pd.CategoricalDtype(categories=['Cred', 'Card', 'Cvas'], ordered=True)\n",
    "dpa_dtype = pd.CategoricalDtype(categories=['PRR', 'ROR', 'IC'], ordered=True)\n",
    "\n",
    "for file in glob.glob('../data/carbide/*/*/*.joblib'):\n",
    "    dataset_type, pt_set, name = file.split('/')[-3:]\n",
    "    dpa_metric = name.rstrip('.joblib').split('_')[-1]\n",
    "    df = read_df(file)\n",
    "\n",
    "    params_df = pd.DataFrame({\n",
    "        'Dataset': [dataset_type.capitalize()],\n",
    "        'PT': [pt_set.capitalize()],\n",
    "        'DPA': [dpa_metric.upper()],\n",
    "        'Size': [len(df)],\n",
    "        'Unique SMILES': [df['SMILES'].nunique()],\n",
    "        '% Toxic': [f'{df[\"Label\"].mean()*100:.2f}'],\n",
    "        'Conf. Score Toxic': [f'{df[df[\"Label\"] == 1][\"Label_weight\"].mean()*100:.0f} | {df[df[\"Label\"] == 1][\"Label_weight\"].std()*100:.0f}'],\n",
    "        'Conf. Score Non-Toxic': [f'{df[df[\"Label\"] == 0][\"Label_weight\"].mean()*100:.0f} | {df[df[\"Label\"] == 0][\"Label_weight\"].std()*100:.0f}'],\n",
    "        'EpS': [f'{df.groupby(\"SMILES\").size().mean():.0f} | {df.groupby(\"SMILES\").size().std():.0f}']\n",
    "    })\n",
    "    prms_df.append(params_df)\n",
    "\n",
    "df = pd.concat(prms_df).reset_index(drop=True)\n",
    "\n",
    "df = df.astype({\n",
    "    'Dataset': dataset_dtype,\n",
    "    'PT': pt_dtype,\n",
    "    'DPA': dpa_dtype,\n",
    "})\n",
    "\n",
    "df = df.sort_values(by=['Dataset', 'PT', 'DPA']).reset_index(drop=True)\n",
    "\n",
    "write_df(df, '../results/analysis/dataset_characterization.tsv')"
   ],
   "id": "e8ccdd95bd65df0a",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bb88bf97f31c151"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T10:48:05.837608Z",
     "start_time": "2026-01-19T10:48:05.822906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LaTeX table\n",
    "\n",
    "df = read_df('../results/analysis/dataset_characterization.tsv')\n",
    "df = pl.from_pandas(df)\n",
    "\n",
    "for ds_type in ['Primary', 'Secondary']:\n",
    "    ds_line = \"\\t\\multirow[t]{9}{*}{\" + ds_type + \"}\"\n",
    "    print(ds_line)\n",
    "\n",
    "    for pt_set in ['Cred', 'Card', 'Cvas']:\n",
    "        pt_line = \"\\t\\t& \\multirow[t]{3}{*}{\" + pt_set + \"}\"\n",
    "        print(pt_line)\n",
    "\n",
    "        for idx, dpa_metric in enumerate(['PRR', 'ROR', 'IC']):\n",
    "            sub_df = df.filter(\n",
    "                (pl.col(\"Dataset\") == ds_type) &\n",
    "                (pl.col(\"PT\") == pt_set) &\n",
    "                (pl.col(\"DPA\") == dpa_metric)\n",
    "            )\n",
    "\n",
    "            n_comp = sub_df[\"Size\"].item()\n",
    "            n_unique = sub_df['Unique SMILES'].item()\n",
    "            frac_toxic = sub_df['% Toxic'].item()\n",
    "            cst_mean, cst_std = sub_df['Conf. Score Toxic'].item().split(\" | \")\n",
    "            csnt_mean, csnt_std = sub_df['Conf. Score Non-Toxic'].item().split(\" | \")\n",
    "            eps_mean, eps_std = sub_df['EpS'].item().split(\" | \")\n",
    "\n",
    "            if idx == 0:\n",
    "                pre = \"  &\"\n",
    "            else:\n",
    "                pre = \"& &\"\n",
    "\n",
    "            empty_lines = \" \" * (3 - len(dpa_metric))\n",
    "\n",
    "            dpa_line = f\"\\t\\t\\t{pre} {dpa_metric} {empty_lines}& {n_comp} & {n_unique} & {frac_toxic:.2f} & {cst_mean} ± {cst_std} & {csnt_mean} ± {csnt_std} & {eps_mean} ± {eps_std} \\\\\\\\\"\n",
    "            print(dpa_line)\n"
   ],
   "id": "d5958f2f124d6601",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\\multirow[t]{9}{*}{Primary}\n",
      "\t\t& \\multirow[t]{3}{*}{Cred}\n",
      "\t\t\t  & PRR & 26314 & 1158 & 57.70 & 28 ± 22 & 42 ± 29 & 23 ± 16 \\\\\n",
      "\t\t\t& & ROR & 26300 & 1158 & 54.49 & 24 ± 20 & 46 ± 31 & 23 ± 16 \\\\\n",
      "\t\t\t& & IC  & 26314 & 1158 & 57.71 & 38 ± 30 & 25 ± 16 & 23 ± 16 \\\\\n",
      "\t\t& \\multirow[t]{3}{*}{Card}\n",
      "\t\t\t  & PRR & 28176 & 1193 & 58.68 & 28 ± 23 & 43 ± 29 & 24 ± 16 \\\\\n",
      "\t\t\t& & ROR & 28154 & 1193 & 55.26 & 25 ± 20 & 47 ± 32 & 24 ± 16 \\\\\n",
      "\t\t\t& & IC  & 28176 & 1193 & 58.68 & 38 ± 30 & 26 ± 17 & 24 ± 16 \\\\\n",
      "\t\t& \\multirow[t]{3}{*}{Cvas}\n",
      "\t\t\t  & PRR & 32206 & 1251 & 58.30 & 32 ± 25 & 45 ± 30 & 26 ± 17 \\\\\n",
      "\t\t\t& & ROR & 32164 & 1250 & 54.16 & 27 ± 22 & 49 ± 32 & 26 ± 17 \\\\\n",
      "\t\t\t& & IC  & 32206 & 1251 & 58.31 & 41 ± 31 & 27 ± 19 & 26 ± 17 \\\\\n",
      "\t\\multirow[t]{9}{*}{Secondary}\n",
      "\t\t& \\multirow[t]{3}{*}{Cred}\n",
      "\t\t\t  & PRR & 37616 & 1788 & 61.46 & 29 ± 22 & 45 ± 29 & 21 ± 16 \\\\\n",
      "\t\t\t& & ROR & 37549 & 1786 & 56.27 & 26 ± 21 & 51 ± 32 & 21 ± 16 \\\\\n",
      "\t\t\t& & IC  & 37616 & 1788 & 61.46 & 42 ± 31 & 26 ± 17 & 21 ± 16 \\\\\n",
      "\t\t& \\multirow[t]{3}{*}{Card}\n",
      "\t\t\t  & PRR & 39866 & 1841 & 61.85 & 30 ± 23 & 45 ± 29 & 22 ± 17 \\\\\n",
      "\t\t\t& & ROR & 39771 & 1839 & 56.49 & 26 ± 22 & 51 ± 32 & 22 ± 17 \\\\\n",
      "\t\t\t& & IC  & 39866 & 1841 & 61.85 & 43 ± 32 & 27 ± 17 & 22 ± 17 \\\\\n",
      "\t\t& \\multirow[t]{3}{*}{Cvas}\n",
      "\t\t\t  & PRR & 45747 & 1988 & 60.92 & 34 ± 26 & 46 ± 30 & 23 ± 17 \\\\\n",
      "\t\t\t& & ROR & 45590 & 1984 & 54.84 & 29 ± 24 & 53 ± 33 & 23 ± 17 \\\\\n",
      "\t\t\t& & IC  & 45747 & 1988 & 60.92 & 45 ± 33 & 28 ± 19 & 23 ± 17 \\\\\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Class distribution analysis",
   "id": "25065c5c92c30dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:01:45.881362Z",
     "start_time": "2026-01-19T13:01:44.671989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Analyse the class (and weights-adjusted) distribution of toxic class\n",
    "At this point of data analysis, a colleague of mine suggested learning polars as an alternative to pandas, so the following section was my learning arc...\n",
    "On a good note, the code is much more readable this way, as extensive groupby statements in pandas are kind of messy\n",
    "\"\"\"\n",
    "\n",
    "df = read_df('../data/carbide/primary/Cred/carbide_prr.joblib')\n",
    "df = pl.from_pandas(df)\n",
    "\n",
    "df = df.with_columns(\n",
    "    Sex=pl.col('Signature').list.get(0),\n",
    "    Age=pl.col('Signature').list.get(1),\n",
    "    Weight=pl.col('Signature').list.get(2),\n",
    ")\n",
    "\n",
    "sdf = (df.group_by(['Sex', 'Label'])\n",
    "    .agg([\n",
    "        pl.col('Label_weight').mean().round(3).alias('Mean LW'),\n",
    "        pl.len().alias('Entries')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('Mean LW') * pl.col('Entries')).round(3).alias('Contribution'),\n",
    "        pl.col('Entries').sum().over('Sex').alias('Total Entries'),\n",
    "        (pl.col('Mean LW') * pl.col('Entries')).sum().over('Sex').round(3).alias('Total Contribution')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('Entries') / pl.col('Total Entries')).round(3).alias('Frac.'),\n",
    "        (pl.col('Contribution') / pl.col('Total Contribution')).round(3).alias('Adj. Frac.'),\n",
    "    ])\n",
    "    .rename({\n",
    "    'Sex': 'Sub-category'\n",
    "    })\n",
    ")\n",
    "sdf = sdf.with_columns(Category=pl.lit('Sex'))\n",
    "\n",
    "adf = (df.group_by(['Age', 'Label'])\n",
    "    .agg([\n",
    "        pl.col('Label_weight').mean().alias('Mean LW'),\n",
    "        pl.len().alias('Entries')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('Mean LW') * pl.col('Entries')).alias('Contribution'),\n",
    "        pl.col('Entries').sum().over('Age').alias('Total Entries'),\n",
    "        (pl.col('Mean LW') * pl.col('Entries')).sum().over('Age').alias('Total Contribution')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('Entries') / pl.col('Total Entries')).alias('Frac.'),\n",
    "        (pl.col('Contribution') / pl.col('Total Contribution')).alias('Adj. Frac.')\n",
    "    ])\n",
    "    .rename({\n",
    "    'Age': 'Sub-category'\n",
    "    })\n",
    ")\n",
    "adf = adf.with_columns(Category=pl.lit('Age'))\n",
    "\n",
    "wdf = (df.group_by(['Weight', 'Label'])\n",
    "    .agg([\n",
    "        pl.col('Label_weight').mean().alias('Mean LW'),\n",
    "        pl.len().alias('Entries')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('Mean LW') * pl.col('Entries')).alias('Contribution'),\n",
    "        pl.col('Entries').sum().over('Weight').alias('Total Entries'),\n",
    "        (pl.col('Mean LW') * pl.col('Entries')).sum().over('Weight').alias('Total Contribution')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('Entries') / pl.col('Total Entries')).alias('Frac.'),\n",
    "        (pl.col('Contribution') / pl.col('Total Contribution')).alias('Adj. Frac.')\n",
    "    ])\n",
    "    .rename({\n",
    "    'Weight': 'Sub-category'\n",
    "    })\n",
    ")\n",
    "wdf = wdf.with_columns(Category=pl.lit('Weight'))\n",
    "\n",
    "class_analysis = pl.concat([sdf, adf, wdf])"
   ],
   "id": "60dadf457bdcccee",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:01:50.005792Z",
     "start_time": "2026-01-19T13:01:49.574975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_analysis = (class_analysis\n",
    "    .with_columns([\n",
    "        pl.col('Mean LW').round(3).alias('Mean LW'),\n",
    "        pl.col('Contribution').round(3).alias('Contribution'),\n",
    "        (pl.col('Frac.') * 100).round(3).alias('Frac.'),\n",
    "        (pl.col('Adj. Frac.') * 100).round(3).alias('Adj. Frac.')])\n",
    "    .rename({\n",
    "        'Label': 'Class'})\n",
    "    .with_columns(\n",
    "        pl.col('Class').cast(pl.String).replace({\n",
    "            '0': 'Non-Toxic',\n",
    "            '1': 'Toxic'}))\n",
    ")\n",
    "\n",
    "class_analysis.write_csv('../results/analysis/class_analysis.tsv', separator='\\t')"
   ],
   "id": "3f65bca386a68b69",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:14:36.256583Z",
     "start_time": "2026-01-19T13:14:36.228220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LaTeX table\n",
    "\n",
    "for number, category in zip([6, 10, 8], ['Sex', 'Age', 'Weight']):\n",
    "    ds_line = \"\\t\\multirow[t]{\" + str(number) + \"}{*}{\" + category + \"}\"\n",
    "    print(ds_line)\n",
    "\n",
    "    if category == 'Sex':\n",
    "        iter_over = ['Male', 'Female', 'Unknown']\n",
    "    elif category == 'Age':\n",
    "        iter_over = ['Children', 'Adolescent', 'Adult', 'Elderly', 'Unknown']\n",
    "    elif category == 'Weight':\n",
    "        iter_over = ['Low', 'Average', 'High', 'Unknown']\n",
    "\n",
    "    for iter in iter_over:\n",
    "        sub_line = \"\\t\\t& \\multirow[t]{2}{*}{\" + iter + \"}\"\n",
    "        print(sub_line)\n",
    "        for idx, tx in enumerate(['Toxic', 'Non-Toxic']):\n",
    "            sub_df = class_analysis.filter(\n",
    "                (pl.col(\"Category\") == category) &\n",
    "                (pl.col(\"Sub-category\") == iter) &\n",
    "                (pl.col(\"Class\") == tx)\n",
    "            )\n",
    "            entries = sub_df['Entries'].item()\n",
    "            mean_lw = sub_df['Mean LW'].item()\n",
    "            frac = sub_df['Frac.'].item()\n",
    "            adj_frac = sub_df['Adj. Frac.'].item()\n",
    "\n",
    "            if idx == 0:\n",
    "                pre = \"  &\"\n",
    "            else:\n",
    "                pre = \"& &\"\n",
    "\n",
    "            empty_lines = \" \" * (9 - len(tx))\n",
    "\n",
    "            line = f\"\\t\\t\\t{pre} {tx} {empty_lines}& {entries} & {mean_lw:.3f} & {frac:.2f} & {adj_frac:.2f} \\\\\\\\\"\n",
    "            print(line)"
   ],
   "id": "2602d8accd2fe6cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\\multirow[t]{6}{*}{Sex}\n",
      "\t\t& \\multirow[t]{2}{*}{Male}\n",
      "\t\t\t  & Toxic     & 4313 & 0.265 & 54.60 & 43.00 \\\\\n",
      "\t\t\t& & Non-Toxic & 3589 & 0.423 & 45.40 & 57.00 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Female}\n",
      "\t\t\t  & Toxic     & 4885 & 0.263 & 59.50 & 48.50 \\\\\n",
      "\t\t\t& & Non-Toxic & 3330 & 0.409 & 40.50 & 51.50 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Unknown}\n",
      "\t\t\t  & Toxic     & 5985 & 0.294 & 58.70 & 48.90 \\\\\n",
      "\t\t\t& & Non-Toxic & 4212 & 0.436 & 41.30 & 51.10 \\\\\n",
      "\t\\multirow[t]{10}{*}{Age}\n",
      "\t\t& \\multirow[t]{2}{*}{Children}\n",
      "\t\t\t  & Toxic     & 1297 & 0.166 & 67.34 & 51.29 \\\\\n",
      "\t\t\t& & Non-Toxic & 629 & 0.324 & 32.66 & 48.71 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Adolescent}\n",
      "\t\t\t  & Toxic     & 1316 & 0.181 & 69.70 & 55.46 \\\\\n",
      "\t\t\t& & Non-Toxic & 572 & 0.334 & 30.30 & 44.54 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Adult}\n",
      "\t\t\t  & Toxic     & 4075 & 0.271 & 56.64 & 45.80 \\\\\n",
      "\t\t\t& & Non-Toxic & 3119 & 0.420 & 43.36 & 54.20 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Elderly}\n",
      "\t\t\t  & Toxic     & 3324 & 0.287 & 51.96 & 42.21 \\\\\n",
      "\t\t\t& & Non-Toxic & 3073 & 0.425 & 48.04 & 57.79 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Unknown}\n",
      "\t\t\t  & Toxic     & 5171 & 0.324 & 58.04 & 49.58 \\\\\n",
      "\t\t\t& & Non-Toxic & 3738 & 0.456 & 41.96 & 50.42 \\\\\n",
      "\t\\multirow[t]{8}{*}{Weight}\n",
      "\t\t& \\multirow[t]{2}{*}{Low}\n",
      "\t\t\t  & Toxic     & 3074 & 0.213 & 56.77 & 41.96 \\\\\n",
      "\t\t\t& & Non-Toxic & 2341 & 0.386 & 43.23 & 58.04 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Average}\n",
      "\t\t\t  & Toxic     & 3188 & 0.220 & 57.90 & 43.30 \\\\\n",
      "\t\t\t& & Non-Toxic & 2318 & 0.397 & 42.10 & 56.70 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{High}\n",
      "\t\t\t  & Toxic     & 2812 & 0.215 & 55.33 & 40.13 \\\\\n",
      "\t\t\t& & Non-Toxic & 2270 & 0.398 & 44.67 & 59.87 \\\\\n",
      "\t\t& \\multirow[t]{2}{*}{Unknown}\n",
      "\t\t\t  & Toxic     & 6109 & 0.365 & 59.25 & 52.85 \\\\\n",
      "\t\t\t& & Non-Toxic & 4202 & 0.473 & 40.75 & 47.15 \\\\\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### RS ratio analysis",
   "id": "a0c51a82263e8eb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:19:49.978839Z",
     "start_time": "2026-01-19T13:19:49.495566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the Recall/Specificity Ratio and compare with toxic class distribution\n",
    "\n",
    "cl_df = pl.read_csv('../results/analysis/class_analysis.tsv', separator='\\t')\n",
    "cl_df = cl_df.filter(pl.col('Class') != 'Non-Toxic')\n",
    "\n",
    "tot_df = read_df('../results/analysis/total.tsv')\n",
    "sex_df = read_df('../results/analysis/sex.tsv')\n",
    "age_df = read_df('../results/analysis/age.tsv')\n",
    "wgt_df = read_df('../results/analysis/weight.tsv')\n",
    "\n",
    "sex_df['Stratification'] = 'Sex'\n",
    "sex_df = sex_df.rename(columns={'Sex':'Cat'})\n",
    "\n",
    "age_df['Stratification'] = 'Age'\n",
    "age_df = age_df.rename(columns={'Age':'Cat'})\n",
    "\n",
    "wgt_df['Stratification'] = 'Weight'\n",
    "wgt_df = wgt_df.rename(columns={'Weight':'Cat'})\n",
    "\n",
    "df = pd.concat([sex_df, age_df, wgt_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "res_df = pl.from_pandas(df)\n",
    "res_df = res_df.filter(pl.col('Series') == \"Unweighted\").drop(['Series', 'Test_Fold', 'Model', 'Descriptors'])\n",
    "\n",
    "res_df_proc = (res_df.group_by(['Stratification', 'Cat', 'Metric'])\n",
    "    .agg(pl.col('Value').mean())\n",
    "    .filter(pl.col('Metric').is_in(['Recall', 'Specificity']))\n",
    "    .pivot(index=['Stratification', 'Cat'], on='Metric')\n",
    "    .with_columns((pl.col('Recall') / pl.col('Specificity')).alias('RS ratio').round(3))\n",
    "    .rename({'Stratification': 'Category', 'Cat': 'Sub-category'})\n",
    ")\n",
    "\n",
    "df = res_df_proc.join(cl_df, on=['Category', 'Sub-category']).drop('Class')\n",
    "\n",
    "df = df.with_columns([\n",
    "    (pl.col('Frac.') / 100).alias('Fraction Toxic'),\n",
    "    (pl.col('Adj. Frac.') / 100).alias('Adjusted Fraction Toxic'),\n",
    "])\n",
    "df = df.drop(['Frac.', 'Adj. Frac.'])\n",
    "\n",
    "df.write_csv('../results/analysis/RS_ratio_analysis.tsv', separator='\\t')"
   ],
   "id": "13d83a6193072640",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predictions differences",
   "id": "f398ea8da3bdb47f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aggregate the results of prediction differences\n",
    "\n",
    "differences = [joblib.load(file) for file in glob.glob('../results/differences/*.joblib')]\n",
    "\n",
    "# aggregate all predictions per SMILES\n",
    "ddc = defaultdict(list)\n",
    "\n",
    "for diff in differences:\n",
    "    for fold, results in diff.items():\n",
    "        for smiles, array in results.items():\n",
    "            ddc[smiles].append(array)\n",
    "\n",
    "# calculate mean per demographic group\n",
    "ddc_cc = {}\n",
    "for smiles, arrays in ddc.items():\n",
    "    ddc_cc[smiles] = np.mean(ddc[smiles], axis=0)\n",
    "\n",
    "# build a DataFrame\n",
    "idc_map = {\n",
    "    0: ('Sex', 'Male'),\n",
    "    1: ('Sex', 'Female'),\n",
    "    2: ('Age', 'Children'),\n",
    "    3: ('Age', 'Adolescent'),\n",
    "    4: ('Age', 'Adult'),\n",
    "    5: ('Age', 'Elderly'),\n",
    "    6: ('Weight', 'Low'),\n",
    "    7: ('Weight', 'Average'),\n",
    "    8: ('Weight', 'High')\n",
    "}\n",
    "\n",
    "df_dc = defaultdict(list)\n",
    "\n",
    "for smiles, array in ddc_cc.items():\n",
    "    for idx, assignment in idc_map.items():\n",
    "        df_dc['SMILES'].append(smiles)\n",
    "        df_dc['Category'].append(assignment[0])\n",
    "        df_dc['Sub-category'].append(assignment[1])\n",
    "        df_dc['Difference'].append(np.round(array[0][idx], 5))\n",
    "\n",
    "df = pd.DataFrame(df_dc)\n",
    "write_df(df, '../results/analysis/prediction_differences.tsv')"
   ],
   "id": "80bb8344cef64449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Models' predictions",
   "id": "27280bd2f542b60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine model prediction analysis with class and RS ratio analysis.\n",
    "\n",
    "sex_df = read_df('../results/analysis/sex.tsv')\n",
    "age_df = read_df('../results/analysis/age.tsv')\n",
    "wgt_df = read_df('../results/analysis/weight.tsv')\n",
    "\n",
    "sex_df['Stratification'] = 'Sex'\n",
    "sex_df = sex_df.rename(columns={'Sex':'Category'})\n",
    "\n",
    "age_df['Stratification'] = 'Age'\n",
    "age_df = age_df.rename(columns={'Age':'Category'})\n",
    "\n",
    "wgt_df['Stratification'] = 'Weight'\n",
    "wgt_df = wgt_df.rename(columns={'Weight':'Category'})\n",
    "\n",
    "df = pd.concat([sex_df, age_df, wgt_df], axis=0).reset_index(drop=True)\n",
    "df = pl.from_pandas(df).rename({'Category': 'Sub-category'})\n",
    "\n",
    "df_ = pl.read_csv('../results/analysis/RS_ratio_analysis.tsv', separator='\\t').rename({'Category': 'Stratification'})\n",
    "df_ = df_.drop(['Entries', 'Mean LW', 'Fraction Toxic', 'RS ratio', 'Recall', 'Specificity'])\n",
    "df_ = (df_.rename({'Adjusted Fraction Toxic': 'AFT'})\n",
    "       .unpivot(on='AFT', index=['Stratification', 'Sub-category'], value_name='Value', variable_name='Metric'))\n",
    "\n",
    "df = (df.drop(['Test_Fold', 'Model', 'Descriptors', 'Series'])\n",
    "      .select(['Stratification', 'Sub-category', 'Metric', 'Value']))\n",
    "\n",
    "df = pl.concat([df, df_])\n",
    "df.write_csv('../results/analysis/models_metrics.tsv', separator='\\t')"
   ],
   "id": "6d2258e99d869e40",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
